{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9438808,"sourceType":"datasetVersion","datasetId":5735509},{"sourceId":11885707,"sourceType":"datasetVersion","datasetId":7401788}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import multiprocessing as mp\n# mp.set_start_method('spawn')  # Set before any other imports or operations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:17.774576Z","iopub.execute_input":"2025-05-27T19:05:17.774748Z","iopub.status.idle":"2025-05-27T19:05:17.779439Z","shell.execute_reply.started":"2025-05-27T19:05:17.774732Z","shell.execute_reply":"2025-05-27T19:05:17.778558Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#bands 4.6.8.11","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:17.780009Z","iopub.execute_input":"2025-05-27T19:05:17.780251Z","iopub.status.idle":"2025-05-27T19:05:17.800509Z","shell.execute_reply.started":"2025-05-27T19:05:17.780228Z","shell.execute_reply":"2025-05-27T19:05:17.799651Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"! ls /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:17.802279Z","iopub.execute_input":"2025-05-27T19:05:17.802595Z","iopub.status.idle":"2025-05-27T19:05:17.942573Z","shell.execute_reply.started":"2025-05-27T19:05:17.802573Z","shell.execute_reply":"2025-05-27T19:05:17.941562Z"}},"outputs":[{"name":"stdout","text":"best_model.pth\nglobal_stats.npz\nlitter_rows_df_invalid_info.csv\nlitter_rows_val_df_invalid_info.csv\nmarida_df_invalid_info.csv\nmarida_test_df_invalid_info.csv\nmarida_val_df_invalid_info.csv\nmodel_30_epochs_ratio_1_20_bs16_iou_081.pth\nmodel_30_epochs_ratio_1_40_bs16_iou_0819.pth\nmodel_50_epochs_ratio_1_20_bs16_test_iou_debris_076_thr0.8.pth\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#%%capture\n! pip install rasterio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:17.943760Z","iopub.execute_input":"2025-05-27T19:05:17.944028Z","iopub.status.idle":"2025-05-27T19:05:23.814957Z","shell.execute_reply.started":"2025-05-27T19:05:17.943994Z","shell.execute_reply":"2025-05-27T19:05:23.814182Z"}},"outputs":[{"name":"stdout","text":"Collecting rasterio\n  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\nCollecting affine (from rasterio)\n  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.4.26)\nRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\nRequirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\nRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.26.4)\nRequirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->rasterio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->rasterio) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24->rasterio) (2024.2.0)\nDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\nInstalling collected packages: affine, rasterio\nSuccessfully installed affine-2.4.0 rasterio-1.4.3\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport sys\nimport shutil\nimport re\nfrom PIL import Image\nimport rasterio\nimport matplotlib.pyplot as plt\nimport dask.array as da\nfrom scipy.ndimage import binary_dilation\nfrom skimage.morphology import disk  # For circular structuring elements\nimport torch\nfrom torchvision import transforms\nimport torchvision.transforms.functional as vF\nimport torch.nn.functional as F\nimport gdown\nfrom tqdm import tqdm\nimport random\n\nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, jaccard_score, hamming_loss, label_ranking_loss, coverage_error, classification_report\nimport sklearn.metrics as metr\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:23.816409Z","iopub.execute_input":"2025-05-27T19:05:23.816721Z","iopub.status.idle":"2025-05-27T19:05:36.049057Z","shell.execute_reply.started":"2025-05-27T19:05:23.816684Z","shell.execute_reply":"2025-05-27T19:05:36.048341Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"pd.set_option(\"display.max_colwidth\", None)  # Show full column values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.049866Z","iopub.execute_input":"2025-05-27T19:05:36.050364Z","iopub.status.idle":"2025-05-27T19:05:36.054177Z","shell.execute_reply.started":"2025-05-27T19:05:36.050338Z","shell.execute_reply":"2025-05-27T19:05:36.053498Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\nfrom torch.utils.data import DataLoader, Dataset\n\ndef set_seed(seed):\n    \"\"\"\n    Set random seeds for NumPy, PyTorch (CPU and GPU), and Python's random module.\n    \n    Args:\n        seed (int): Seed value for RNGs\n    \"\"\"\n    # Python random\n    random.seed(seed)\n    \n    # NumPy\n    np.random.seed(seed)\n    \n    # PyTorch CPU\n    torch.manual_seed(seed)\n    \n    # PyTorch GPU (CUDA)\n    torch.cuda.manual_seed(seed)  # Current GPU\n    torch.cuda.manual_seed_all(seed)  # All GPUs\n    \n    # Ensure deterministic behavior\n    #torch.use_deterministic_algorithms(True)\n    #torch.backends.cudnn.deterministic = True\n    #torch.backends.cudnn.benchmark = False\n\ndef worker_init_fn(worker_id):\n    \"\"\"\n    Initialize random seed for DataLoader workers.\n    Ensures each worker has a unique but reproducible RNG state.\n    \n    Args:\n        worker_id (int): Worker ID\n    \"\"\"\n    max_seed = 2**32 - 1  # NumPy seed limit\n    worker_seed = (torch.initial_seed() + worker_id) % max_seed\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.055039Z","iopub.execute_input":"2025-05-27T19:05:36.055383Z","iopub.status.idle":"2025-05-27T19:05:36.074890Z","shell.execute_reply.started":"2025-05-27T19:05:36.055354Z","shell.execute_reply":"2025-05-27T19:05:36.074158Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def create_LR_dataframe(splits_path, mode='train'):\n    split_images_files = {'train' : 'train_X.txt', 'val' : 'val_X.txt', 'test' : 'test_X.txt'}\n    split_masks_files = {'train' : 'train_masks.txt', 'val' : 'val_masks.txt', 'test' : 'test_masks.txt'}  \n    with open(os.path.join(splits_path, split_images_files[mode]), \"r\") as file:\n        images = file.readlines()  # Reads all lines into a list\n        images = [image.strip() for image in images]  # Remove any trailing newline characters\n    with open(os.path.join(splits_path, split_masks_files[mode]), \"r\") as file:\n        masks = file.readlines()  # Reads all lines into a list\n        masks = [mask.strip() for mask in masks]  # Remove any trailing newline characters\n    df = pd.DataFrame({'image' : images, 'mask' : masks})\n    return df\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.078092Z","iopub.execute_input":"2025-05-27T19:05:36.078454Z","iopub.status.idle":"2025-05-27T19:05:36.100545Z","shell.execute_reply.started":"2025-05-27T19:05:36.078429Z","shell.execute_reply":"2025-05-27T19:05:36.099815Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# from Sagar and Navodita's code\ndef compute_fdi_from_tiff(tiff_path):\n    with rasterio.open(tiff_path) as src:\n        # Assuming band order follows your stacked TIFF (B1–B12, skipping B10 if needed)\n        # Band indices are 1-based in rasterio\n        R665 = src.read(4)    # B4\n        R859 = src.read(9)    # B8A\n        R1610 = src.read(10)  # B11\n        # Convert to float and mask invalid values\n        R665 = R665.astype(np.float32)\n        R859 = R859.astype(np.float32)\n        R1610 = R1610.astype(np.float32)\n        # Calculate FDI\n        FDI = R859 - (R665 + ((R1610 - R665) * (859 - 665) / (1610 - 665)))\n        return FDI\n\ndef cvt_to_fdi(images):\n    fdi_images = []\n    batch = images.copy()\n    if len(images.shape) == 3 : \n        batch = batch[None, :]\n    for i in range(batch.shape[0]):\n        im = batch[i]\n        R665 = im[3]   # B4\n        R859 = im[8]   # B8A\n        R1610 = im[0]  # B11\n        # Convert to float and mask invalid values\n        R665 = R665.astype(np.float32)\n        R859 = R859.astype(np.float32)\n        R1610 = R1610.astype(np.float32)\n        # Calculate FDI\n        FDI = R859 - (R665 + ((R1610 - R665) * (859 - 665) / (1610 - 665)))\n        fdi_images.append(FDI)\n    return np.array(fdi_images)\n    \ndef compute_ndwi(tiff_path):\n    with rasterio.open(tiff_path) as src:\n        Rgreen = src.read(3).astype(np.float32)  # Band 3 (Green)\n        Rnir = src.read(8).astype(np.float32)    # Band 8 (NIR)\n        ndwi = (Rgreen - Rnir) / (Rgreen + Rnir + 1e-6)  # avoid divide-by-zero\n    return ndwi\ndef plot_fdi(fdi_array, ndwi, img_path, mask_path):\n    with rasterio.open(img_path) as src:\n        rgb = src.read([4, 3, 2])\n        rgb = np.transpose(rgb, (1, 2, 0))\n    # Normalization\n    rgb = rgb.astype(np.float32)\n    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n    with rasterio.open(mask_path) as src:\n        mask = src.read(1)\n    # Create binary mask\n    mask_binary = mask > 0\n    # Plot side-by-side\n    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n    axs[0].imshow(rgb)\n    axs[0].set_title(\"RGB Patch\")\n    axs[1].imshow(mask_binary)  #, cmap='gray')\n    axs[1].set_title(\"Binary Mask (._cl.tif)\")\n    axs[2].imshow(fdi_array)\n    axs[2].set_title(\"FDI\")\n    axs[3].imshow(ndwi)\n    axs[3].set_title(\"NDWI\")\n    for ax in axs:\n        ax.axis('off')\n\n    # with rasterio.open(patch_path) as patch_src:\n    #     rgb = patch_src.read([4, 3, 2])  # Use bands B4, B3, B2 for RGB\n    #     rgb = np.transpose(rgb, (1, 2, 0))\n    #     rgb = (rgb - np.min(rgb)) / (np.max(rgb) - np.min(rgb) + 1e-6)\n    import matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\n# List of image and mask file paths (replace with your file paths)\nimage_mask_pairs = [\n    ('path_to_image1.jpg', 'path_to_mask1.png'),\n    ('path_to_image2.jpg', 'path_to_mask2.png'),\n    # Add more pairs as needed\n]\n\n\ndef cvt_RGB(images):\n    rgb_images = []\n    for i in range(images.shape[0]):\n        rgb = images[i][[4-1, 3-1, 2-1]] # Use bands B4, B3, B2 for RGB\n        rgb = np.transpose(rgb, (1, 2, 0))\n        rgb = (rgb - np.min(rgb)) / (np.max(rgb) - np.min(rgb) + 1e-6)\n        rgb_images.append(rgb)\n    return np.array(rgb_images)\n\ndef display(images, masks):\n    # Determine the number of pairs\n    num_pairs = images.shape[0]\n\n    # Calculate layout: use 2 columns per pair (image + mask), adjust rows dynamically\n    cols = 2  # One column for image, one for mask\n    rows = num_pairs  # One row per pair\n\n    # Create a figure with subplots\n    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n\n    # Handle case of single pair (axes is not a 2D array)\n    if num_pairs == 1:\n        axes = np.array([axes]).reshape(1, -1)\n\n    # Iterate through each pair and display image and mask\n    for idx, (image, mask) in enumerate(zip(images, masks)):\n\n        # Display the original image\n        axes[idx, 0].imshow(image)\n        axes[idx, 0].set_title(f'Image {idx + 1}')\n        axes[idx, 0].axis('off')  # Hide axes\n    \n        # Display the segmentation mask\n        axes[idx, 1].imshow(mask, cmap='gray')  # Adjust cmap if needed\n        axes[idx, 1].set_title(f'Mask {idx + 1}')\n        axes[idx, 1].axis('off')  # Hide axes\n\n    # Adjust layout to prevent overlap\n    plt.tight_layout()\n    \n    # Show the plot\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.101605Z","iopub.execute_input":"2025-05-27T19:05:36.102370Z","iopub.status.idle":"2025-05-27T19:05:36.124525Z","shell.execute_reply.started":"2025-05-27T19:05:36.102335Z","shell.execute_reply":"2025-05-27T19:05:36.123782Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\ndef extract_date_tile(filename):\n    \"\"\"Extract date and tile from filename using regex.\"\"\"\n    pattern = r'^(\\d{1,2}-\\d{1,2}-\\d{2})_([A-Z0-9]+)_\\d+$'\n    match = re.match(pattern, filename)\n    if not match:\n        raise ValueError(f\"Invalid filename format: {filename}\")\n    return match.groups()  # Returns tuple (date, tile)\n\ndef create_marida_df(data_path, mode='train'):\n    \"\"\"Create DataFrame from MARIDA dataset files.\"\"\"\n    # Determine split file based on mode\n    split_files = {'train': 'train_X.txt', 'val': 'val_X.txt', 'test': 'test_X.txt'}\n    items_list_path = os.path.join(data_path, 'splits', split_files[mode])\n\n    # Read items list\n    with open(items_list_path, 'r') as file:\n        items = [item.strip() for item in file]\n\n    # Base path for patches\n    items_path = os.path.join(data_path, 'patches')\n\n    # Prepare data lists\n    data = {\n        'image': [],\n        'mask': [],\n        'confidence': [],\n        'date': [],\n        'tile': []\n    }\n\n    # Process each item\n    for item in items:\n        tile = \"_\".join(item.split(\"_\")[:-1])\n        tile_path = os.path.join(items_path, f\"S2_{tile}\")\n\n        # Define file paths\n        base_name = f'S2_{item}'\n        paths = {\n            'image': os.path.join(tile_path, f'{base_name}.tif'),\n            'mask': os.path.join(tile_path, f'{base_name}_cl.tif'),\n            'confidence': os.path.join(tile_path, f'{base_name}_conf.tif')\n        }\n\n        # Check if all files exist\n        if all(os.path.exists(p) for p in paths.values()):\n            data['image'].append(paths['image'])\n            data['mask'].append(paths['mask'])\n            data['confidence'].append(paths['confidence'])\n            date, tile = extract_date_tile(item)\n            data['date'].append(date)\n            data['tile'].append(tile)\n\n    return pd.DataFrame(data)\n\n# MARIDA labels dictionary\nMARIDA_LABELS = {\n    i: label for i, label in enumerate([\n        'Marine Debris', 'Dense Sargassum', 'Sparse Sargassum', 'Natural Organic Material',\n        'Ship', 'Clouds', 'Marine Water', 'Sediment-Laden Water', 'Foam', 'Turbid Water',\n        'Shallow Water', 'Waves', 'Cloud Shadows', 'Wakes', 'Mixed Water'\n    ], 1)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.125487Z","iopub.execute_input":"2025-05-27T19:05:36.125795Z","iopub.status.idle":"2025-05-27T19:05:36.148437Z","shell.execute_reply.started":"2025-05-27T19:05:36.125770Z","shell.execute_reply":"2025-05-27T19:05:36.147562Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import rasterio\nimport numpy as np\n\ndef compute_invalid_pixels(image_paths, mask_paths):\n    \"\"\"\n    Compute per-band statistics for Sentinel-2 L1C ACOLITE-processed images using segmentation masks.\n    Creates a mask to exclude invalid pixels (NaNs, negative values, specified no-data value).\n    \n    Parameters:\n    - image_paths: List of paths to image files (e.g., GeoTIFF with 11 bands).\n    - mask_paths: List of paths to segmentation mask files (single-band, integer class labels).\n    - class_labels: List of mask class labels to include (e.g., [1, 2] for vegetation and water).\n                   If None, include all non-zero labels (excluding background).\n    - invalid_value: Optional value to treat as invalid in images (e.g., -9999).\n    \n    Returns:\n    - mean_per_band: List of per-band means for each image.\n    - std_per_band: List of per-band standard deviations for each image.\n    \"\"\"\n    mean_per_band = []  # Initialize as list\n    std_per_band = []   # Initialize as list\n    positive_pixels = []\n    tot_pixels = [];\n    images_with_invalid_pixels = []\n    black_list = []\n    accumulator = None\n    no_data_pixels = []\n    neg_pixels = []\n    nan_pixels = []\n    gt1_pixels = []\n    imgs_with_invalid = []\n    positive_pixels = []\n    min_vals = []\n    max_vals = []\n    for img_path, mask_path in zip(image_paths, mask_paths):\n        # Load image and mask\n        with rasterio.open(img_path) as src_img, rasterio.open(mask_path) as src_mask:\n            image = src_img.read()  # Shape: (bands, height, width)\n            mask = src_mask.read(1)  # Shape: (height, width)\n            \n            # Convert image to float for NaN handling\n            image = image.astype(float)\n\n            nan_mask = np.isnan(image)\n            neg_mask = (image < 0)\n            too_big_mask = (image > 1)\n            no_data_mask = (image == src_img.nodata)\n            nan_pixels.append(np.sum(nan_mask))\n            neg_pixels.append(np.sum(neg_mask))\n            gt1_pixels.append(np.sum(too_big_mask))\n            no_data_pixels.append(np.sum(no_data_mask))\n            imgs_with_invalid.append(img_path)\n            positive_pixels.append(np.sum(mask > 0))\n            min_vals.append(np.min(image))\n            max_vals.append(np.max(image))\n    df = pd.DataFrame({'image' : imgs_with_invalid, 'no data pixels' : no_data_pixels, 'negative pixels' : neg_pixels,\n                      'nan pixels' : nan_pixels, 'high value pixels' :  gt1_pixels, 'debris pixels' : positive_pixels,\n                      'min values' : min_vals, 'max values' : max_vals})\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.149324Z","iopub.execute_input":"2025-05-27T19:05:36.149848Z","iopub.status.idle":"2025-05-27T19:05:36.175777Z","shell.execute_reply.started":"2025-05-27T19:05:36.149821Z","shell.execute_reply":"2025-05-27T19:05:36.175090Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#Setting batch size\nbatch_size = 16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.176684Z","iopub.execute_input":"2025-05-27T19:05:36.176902Z","iopub.status.idle":"2025-05-27T19:05:36.269725Z","shell.execute_reply.started":"2025-05-27T19:05:36.176885Z","shell.execute_reply":"2025-05-27T19:05:36.268810Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def compute_stats(image_files, discard_negatives = False, discard_gt_1 = False):\n    bands_std = []\n    bands_mean = []\n    valid_pixels = []\n\n    for band_idx in range(11):\n        arrays = [da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto')\n                  for f in image_files]\n        stack = da.stack(arrays)\n        #valid = (stack != rasterio.open(image_files[0]).nodata) & (stack >= 0)\n        if discard_negatives and  discard_gt_1: \n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                              & (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') >= 0) & \n                              (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') <= 1) \n                              for f in image_files])\n        elif discard_gt_1 :\n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                              & (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') <= 1)  \n                              for f in image_files])\n        elif discard_negatives:\n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                  & (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') >= 0) \n                  for f in image_files])\n        else :\n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                  for f in image_files])\n                         \n        # Compute number of valid pixels\n        valid_count = da.sum(valid).compute()\n        valid_pixels.append(valid_count)\n        mean = da.nanmean(stack[valid]).compute()\n        std = da.nanstd(stack[valid]).compute()\n        bands_mean.append(mean)\n        bands_std.append(std)\n        print(f\"Band {band_idx} - Mean: {mean}, Std: {std}\")\n    return {'mean' : np.array(bands_mean), 'std': np.array(bands_std),'valid pixels' : np.array(valid_pixels) }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.270640Z","iopub.execute_input":"2025-05-27T19:05:36.270916Z","iopub.status.idle":"2025-05-27T19:05:36.283914Z","shell.execute_reply.started":"2025-05-27T19:05:36.270897Z","shell.execute_reply":"2025-05-27T19:05:36.283287Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def computing_labeled_pixels_stats(mask_paths):\n    arrays = [da.from_array(rasterio.open(f).read(1), chunks='auto')\n                  for f in mask_paths]\n    stack = da.stack(arrays)\n    valid = stack > 0\n    labeled_count = da.sum(valid).compute()\n    return labeled_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.284647Z","iopub.execute_input":"2025-05-27T19:05:36.284866Z","iopub.status.idle":"2025-05-27T19:05:36.306558Z","shell.execute_reply.started":"2025-05-27T19:05:36.284849Z","shell.execute_reply":"2025-05-27T19:05:36.305876Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def compute_invalid_mask(path):\n    with rasterio.open(path) as src:\n        image = src.read()\n        \n        invalid_mask = image == src.nodata\n        invalid_mask |= np.isnan(image)\n        invalid_mask |= image < 0\n        invalid_mask |= image > 1\n        invalid_mask = np.any(invalid_mask, axis=0)\n        return invalid_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.307216Z","iopub.execute_input":"2025-05-27T19:05:36.307499Z","iopub.status.idle":"2025-05-27T19:05:36.323046Z","shell.execute_reply.started":"2025-05-27T19:05:36.307481Z","shell.execute_reply":"2025-05-27T19:05:36.322337Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def get_invalid_mask(image, no_data):\n    invalid_mask = image == no_data\n    invalid_mask |= np.isnan(image)\n    invalid_mask |= image < -1.5\n    invalid_mask |= image > 1.5\n    #invalid_mask = np.any(invalid_mask, axis=0)\n    return invalid_mask  #torch.fromnumpy(invalid_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.323883Z","iopub.execute_input":"2025-05-27T19:05:36.324479Z","iopub.status.idle":"2025-05-27T19:05:36.339815Z","shell.execute_reply.started":"2025-05-27T19:05:36.324449Z","shell.execute_reply":"2025-05-27T19:05:36.339020Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def select_bg_pixels(image, debris_mask, r1=5, r2=20, target_ratio=5):\n    H, W = debris_mask.shape\n    \n    #target_ratio = 5  # Debris-to-background ratio (1:5)\n\n    # Create structuring elements (circular or square)\n    se_r1 = disk(r1) if r1 > 0 else np.ones((1, 1))  # Inner dilation kernel\n    se_r2 = disk(r2)                         # Outer dilation kernel\n    #print('before binary dilation')\n    # Dilate debris mask with r1 and r2\n    dilated_r1 = binary_dilation(debris_mask, structure=se_r1)\n    dilated_r2 = binary_dilation(debris_mask, structure=se_r2)\n    #print('before anular mask')\n    # Compute annular region: pixels in dilated_r2 but not in dilated_r1\n    annular_mask = dilated_r2 & ~dilated_r1\n\n    # Sample background pixels from annular region\n    valid_background_coords = np.where(annular_mask)\n    num_debris = np.sum(debris_mask)\n    num_background = min(len(valid_background_coords[0]), num_debris * target_ratio)\n    if num_background > 0:\n        sample_idx = np.random.choice(len(valid_background_coords[0]), size=num_background, replace=False)\n        background_coords = [(valid_background_coords[0][i], valid_background_coords[1][i]) for i in sample_idx]\n    else:\n        print(\"Warning: No valid background pixels in annular region. Increase r2 or check mask.\")\n\n    # Create background mask (optional, for visualization or training)\n    background_mask = np.zeros_like(debris_mask)\n    for x, y in background_coords:\n        background_mask[x, y] = 1\n    return background_mask\n\n# Optional: Filter by features (e.g., RGB values for water-like pixels)\n# Example: If image is RGB, filter pixels with low green channel (common for water)\n# image = ...  # Your RGB or multispectral image\n# valid_background = [coord for coord in background_coords if image[coord[0], coord[1], 1] < threshold]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.340588Z","iopub.execute_input":"2025-05-27T19:05:36.340776Z","iopub.status.idle":"2025-05-27T19:05:36.362219Z","shell.execute_reply.started":"2025-05-27T19:05:36.340761Z","shell.execute_reply":"2025-05-27T19:05:36.361586Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def batch_process_marida_masks(masks, dataset_ids, device='cpu'):\n    \"\"\"\n    Process masks for dataset_id == 0 (MARIDA) at the batch level.\n    - Set classes [1, 2, 3, 4, 9] to 2 (debris).\n    - Set class 0 to 0 (unlabeled), other classes to 1 (non-debris).\n    \n    Args:\n        masks: Tensor [batch_size, H, W] (integer-valued masks)\n        dataset_ids: Tensor [batch_size] (dataset IDs)\n        device: Device for PyTorch operations ('cpu' or 'cuda')\n    \n    Returns:\n        marida_masks: Tensor [batch_size, H, W] with values 0, 1, 2\n    \"\"\"\n    batch_size, H, W = masks.shape\n    marida_masks = torch.zeros_like(masks, dtype=torch.int64, device=device)\n    \n    # Identify masks with dataset_id == 0\n    marida_mask = (dataset_ids == 0)  # [batch_size], boolean\n    if not marida_mask.any():\n        return marida_masks\n    \n    # Select masks for dataset_id == 0\n    selected_masks = masks[marida_mask]  # [num_marida, H, W]\n    \n    # Set classes [1, 2, 3, 4, 9] to 2\n    debris_classes = torch.tensor([1, 2, 3, 4, 9], device=device)\n    is_debris = torch.isin(selected_masks, debris_classes)  # [num_marida, H, W]\n    marida_masks[marida_mask] = torch.where(\n        is_debris,\n        torch.tensor(2, dtype=torch.int64, device=device),\n        selected_masks  # Temporarily keep original values\n    )\n    # for idx in range( marida_masks[marida_mask].shape[0]):\n    #     print(f' {idx} has {torch.sum(is_debris[idx])} : {torch.unique(marida_masks[marida_mask][idx])}')\n    # Set non-zero, non-debris pixels to 1\n    marida_masks[marida_mask] = torch.where(\n        (marida_masks[marida_mask] != 0) & (marida_masks[marida_mask] != 2),\n        torch.tensor(1, dtype=torch.int64, device=device),\n        marida_masks[marida_mask]\n    )\n    # print('only 3 values : ')\n    # for idx in range( marida_masks[marida_mask].shape[0]):\n    #     print(f' {idx} has {torch.sum(is_debris[idx])} : {torch.unique(marida_masks[marida_mask][idx])}')\n    marida_masks[marida_mask] = marida_masks[marida_mask] - 1\n    #print('after subtr')\n    # for idx in range( marida_masks[marida_mask].shape[0]):\n    #     print(f' {idx} has {torch.sum(is_debris[idx])} : {torch.unique(marida_masks[marida_mask][idx])}')\n    return marida_masks\n\n\n\n# # Custom collate function\n# def custom_collate_fn(batch):\n#     images, masks, dataset_ids = zip(*batch)\n#     images = torch.stack(images)\n#     masks = torch.stack(masks)\n#     dataset_ids = torch.tensor(dataset_ids, dtype=torch.long)\n    \n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#     images, masks, dataset_ids = images.to(device), masks.to(device), dataset_ids.to(device)\n    \n#     final_masks = batch_select_bg_pixels(images, masks, dataset_ids, r1=5, r2=20, \n#                                          target_ratio=5, threshold=0.5, device=device)\n    \n#     return images, masks, final_masks, dataset_ids\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.363111Z","iopub.execute_input":"2025-05-27T19:05:36.363406Z","iopub.status.idle":"2025-05-27T19:05:36.384991Z","shell.execute_reply.started":"2025-05-27T19:05:36.363381Z","shell.execute_reply":"2025-05-27T19:05:36.384089Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\ndef torch_dilate(mask, kernel_size, device='cpu'):\n    \"\"\"Apply dilation to a batch of masks using PyTorch convolution.\"\"\"\n    kernel = torch.ones(1, 1, kernel_size, kernel_size, device=device, dtype=torch.float32)\n    mask = mask.float().unsqueeze(1)  # [batch_size, 1, H, W]\n    dilated = torch.nn.functional.conv2d(mask, kernel, padding=kernel_size // 2) > 0\n    return dilated.squeeze(1).bool()  # [batch_size, H, W]\n\ndef batch_select_bg_pixels(images, masks, dataset_ids, r1=5, r2=20, target_ratio=5, threshold=None, device='cpu'):\n    \"\"\"\n    Compute annular background masks for a batch of masks, only for dataset_id == 1.\n    - Set debris pixels (masks == 1) to 2 in bg_masks.\n    - Set randomly sampled annular pixels to 1 in bg_masks.\n    \n    Args:\n        images: Tensor [batch_size, C, H, W] \n        masks: Tensor [batch_size, H, W] (binary debris masks)\n        dataset_ids: Tensor [batch_size] (dataset IDs)\n        r1, r2: Radii for inner and outer dilation\n        target_ratio: Debris-to-background pixel ratio\n        threshold: Optional threshold for filtering (e.g., green channel)\n        device: Device for PyTorch operations ('cpu' or 'cuda')\n    \n    Returns:\n        bg_masks: Tensor [batch_size, H, W] with values 0 (default), 1 (background), 2 (debris)\n    \"\"\"\n\n    batch_size, H, W = masks.shape\n    # Initialize bg_masks with zeros (int64 to support values 0, 1, 2)\n    bg_masks = torch.zeros_like(masks, dtype=torch.int64, device=device)\n    \n    # Identify masks to process (dataset_id == 1)\n    valid_mask = (dataset_ids == 1)  # [batch_size], boolean{\n    #print(f'LR indices {valid_mask}')\n    if not valid_mask.any():\n        return bg_masks  # Return zeros if no masks need processing\n    \n    # Select masks for dataset_id == 1\n    selected_masks = masks[valid_mask]  # [num_valid, H, W]\n    # for idx in range(selected_masks.shape[0]):\n    #     print(f'num debris pixels : {torch.sum(selected_masks[idx])}')\n    # Set debris pixels to 2 for selected masks\n    bg_masks[valid_mask] = selected_masks * 2  # Where selected_masks == 1, set bg_masks to 2\n    \n    # Perform dilation on selected masks\n    dilated_r1 = torch_dilate(selected_masks, 2 * r1 + 1, device=device)  # [num_valid, H, W]\n    dilated_r2 = torch_dilate(selected_masks, 2 * r2 + 1, device=device)  # [num_valid, H, W]\n    annular_masks = dilated_r2 & ~dilated_r1  # [num_valid, H, W]\n    \n    # Sample background pixels for each selected mask\n    for idx in range(annular_masks.shape[0]):\n        valid_coords = torch.where(annular_masks[idx])  # Tuple of (row, col) indices\n        #print(f'unique values in mask {idx} : {torch.unique(selected_masks[idx])}')\n        num_debris = torch.sum(selected_masks[idx] > 0).item()\n        #print(f'num debris for index {idx} : {num_debris}')\n        num_background = min(len(valid_coords[0]), int(num_debris * target_ratio))\n        \n        if num_background > 0:\n            # Randomly sample indices and set to 1\n            sample_indices = torch.randperm(len(valid_coords[0]), device=device)[:num_background]\n            bg_masks[valid_mask.nonzero(as_tuple=True)[0][idx], \n                     valid_coords[0][sample_indices], \n                     valid_coords[1][sample_indices]] = 1\n        else :\n            print(f'no background selected for index {idx}. Num debrid : {num_debris} Num background : {num_background}')\n            print(f'valid coords {len(valid_coords)}')\n            print(f'unique valus : {torch.unique(selected_masks[idx])}')\n    \n    # # Optional: Filter by image features (e.g., green channel) for dataset_id == 1\n    # if threshold is not None and images is not None:\n    #     valid_pixels = images[valid_mask, 1, :, :] < threshold  # Green channel\n    #     # Only apply filtering to background pixels (value 1), preserve debris pixels (value 2)\n    #     bg_masks[valid_mask] = torch.where(\n    #         bg_masks[valid_mask] == 1,\n    #         bg_masks[valid_mask] & valid_pixels,\n    #         bg_masks[valid_mask]\n    #     )\n    bg_masks[valid_mask] = bg_masks[valid_mask] - 1\n    return bg_masks\n\n# Custom collate function\ndef custom_collate_fn(batch):\n    # print(f'custom collate function batch {len(batch)}')\n    # print(f'custom collate function batch type {type(batch)}')\n    # print(f'custom collate function batch[1] type {type(batch[1])}')\n    # print(f'custom collate function batch[1] len  {len(batch[1])}')\n    images, masks, dataset_ids = zip(*batch)\n    images = torch.stack(images)  # [batch_size, C, H, W]\n    masks = torch.stack(masks)    # [batch_size, H, W]\n    dataset_ids = torch.tensor(dataset_ids, dtype=torch.long)  # [batch_size]\n    \n    # Move to GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    images, masks, dataset_ids = images.to(device), masks.to(device), dataset_ids.to(device)\n    \n    # Compute background masks\n    lr_masks = batch_select_bg_pixels(images, masks, dataset_ids, r1=5, r2=20, \n                                      target_ratio=LR_ratio, device=device)\n    marida_masks = batch_process_marida_masks(masks, dataset_ids, device=device)\n    masks = lr_masks + marida_masks\n    \n    return images, masks, dataset_ids\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.385888Z","iopub.execute_input":"2025-05-27T19:05:36.386132Z","iopub.status.idle":"2025-05-27T19:05:36.403042Z","shell.execute_reply.started":"2025-05-27T19:05:36.386115Z","shell.execute_reply":"2025-05-27T19:05:36.402244Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Seeding for reproducibility\nseed = 42\nset_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.403851Z","iopub.execute_input":"2025-05-27T19:05:36.404052Z","iopub.status.idle":"2025-05-27T19:05:36.430630Z","shell.execute_reply.started":"2025-05-27T19:05:36.404019Z","shell.execute_reply":"2025-05-27T19:05:36.429921Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# %%capture\n# # Download some pre-computed data \n\n#file_id = \"10bMAQaV2-EXCu52ON-6m0qh7u7__v-hH\"\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/marida_df_invalid_info.csv', quiet=False)\n#file_id = '19VzQze4sBt76ylEcishVQNpGIFYSkseT'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/marida_val_df_invalid_info.csv', quiet=False)\n#file_id = '1CvUC8FAqj1aUV8fwrTljU3mC-geWz0it'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/marida_test_df_invalid_info.csv', quiet=False)\n#file_id = \"1YTJmy8X-xIo8dV7Qpq4h7wOi7kUAW4sw\"\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/litter_rows_df_invalid_info.csv', quiet=False)\n#file_id = '1CzvC9VLbzqyh9LbhyxWhtIHaz7o1hmak'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/litter_rows_val_df_invalid_info.csv', quiet=False)\n#file_id = '1wrD41CDQud69AMOyHigw0-DR85Id4zDM'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/global_stats.npz', quiet=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.431501Z","iopub.execute_input":"2025-05-27T19:05:36.431759Z","iopub.status.idle":"2025-05-27T19:05:36.436677Z","shell.execute_reply.started":"2025-05-27T19:05:36.431731Z","shell.execute_reply":"2025-05-27T19:05:36.435965Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# # check that the \n# ! ls /kaggle/input/litter-windrows-patches\n# # add the lr dataset to path to import code to prepare the dataset\n# sys.path.append('/kaggle/input/litter-windrows-patches')\n# # import functions to prepare dataset\n# from prepare_dataset import  get_image_and_mask_paths, split_and_save_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.441281Z","iopub.execute_input":"2025-05-27T19:05:36.441501Z","iopub.status.idle":"2025-05-27T19:05:36.457130Z","shell.execute_reply.started":"2025-05-27T19:05:36.441486Z","shell.execute_reply":"2025-05-27T19:05:36.456350Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"#! git clone https://github.com/sheikhazhanmohammed/SADMA.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.457991Z","iopub.execute_input":"2025-05-27T19:05:36.458282Z","iopub.status.idle":"2025-05-27T19:05:36.471654Z","shell.execute_reply.started":"2025-05-27T19:05:36.458254Z","shell.execute_reply":"2025-05-27T19:05:36.471005Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"#sys.path.append('/kaggle/working/SADMA')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.472199Z","iopub.execute_input":"2025-05-27T19:05:36.472436Z","iopub.status.idle":"2025-05-27T19:05:36.488585Z","shell.execute_reply.started":"2025-05-27T19:05:36.472417Z","shell.execute_reply":"2025-05-27T19:05:36.487710Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# # define a variable for the lr dataset\n# LW_path = '/kaggle/input/litter-windrows-patches'\n# lr_images, lr_masks = get_image_and_mask_paths(LW_path)\n# ! mkdir ./LR_splits\n# split_and_save_data(lr_images, lr_masks, './LR_splits' )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.489498Z","iopub.execute_input":"2025-05-27T19:05:36.489783Z","iopub.status.idle":"2025-05-27T19:05:36.505640Z","shell.execute_reply.started":"2025-05-27T19:05:36.489758Z","shell.execute_reply":"2025-05-27T19:05:36.504805Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# ! ls ./LR_splits/splits\n# LR_splits_path = '/kaggle/working/LR_splits/splits'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.506762Z","iopub.execute_input":"2025-05-27T19:05:36.506960Z","iopub.status.idle":"2025-05-27T19:05:36.521620Z","shell.execute_reply.started":"2025-05-27T19:05:36.506945Z","shell.execute_reply":"2025-05-27T19:05:36.520776Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# from IPython.display import display\n\n# with open(LR_splits_path+'/train_X.txt', \"r\") as file:\n#     display(file.read())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.522507Z","iopub.execute_input":"2025-05-27T19:05:36.522710Z","iopub.status.idle":"2025-05-27T19:05:36.538896Z","shell.execute_reply.started":"2025-05-27T19:05:36.522694Z","shell.execute_reply":"2025-05-27T19:05:36.538130Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"! ls /kaggle/input/marida-marine-debrish-dataset\nMARIDA_path = '/kaggle/input/marida-marine-debrish-dataset'\n! ls /kaggle/input/litter-windrows-patches\nLR_splits_path = '/kaggle/input/litter-windrows-patches/binary_splits'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.539726Z","iopub.execute_input":"2025-05-27T19:05:36.539975Z","iopub.status.idle":"2025-05-27T19:05:36.835400Z","shell.execute_reply.started":"2025-05-27T19:05:36.539953Z","shell.execute_reply":"2025-05-27T19:05:36.834553Z"}},"outputs":[{"name":"stdout","text":"labels_mapping.txt  patches  shapefiles  splits\nannotation     multiclass_splits  prepare_dataset.ipynb\nbinary_splits  patches\t\t  README.md\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# MARIDA dataframe\nmarida_df = create_marida_df(MARIDA_path)\n#marida_df_invalid = compute_invalid_pixels(marida_df['image'].tolist(), marida_df['mask'].tolist())\n#marida_df_invalid.to_csv('/kaggle/working/marida_with_invalid.csv')\nmarida_df_invalid = pd.read_csv('/kaggle/working/marida_df_invalid_info.csv')\nmarida_df_F = marida_df.drop(marida_df_invalid[marida_df_invalid['nan pixels']>0].index)\n\n# MARIDA val dataframe\nmarida_val_df = create_marida_df(MARIDA_path, 'val')\n#marida_val_df_invalid = compute_invalid_pixels(marida_val_df['image'].tolist(), marida_val_df['mask'].tolist())\n#marida_val_df_invalid.to_csv('/kaggle/working/marida_val_df_invalid.csv')\nmarida_val_df_invalid =pd.read_csv('/kaggle/working/marida_val_df_invalid_info.csv')\nmarida_val_df_F = marida_val_df.drop(marida_val_df_invalid[marida_val_df_invalid['nan pixels'] > 0].index)\n\n# MARIDA test dataframe\nmarida_test_df = create_marida_df(MARIDA_path, 'test')\n#marida_test_df_invalid = compute_invalid_pixels(marida_test_df['image'].tolist(), marida_test_df['mask'].tolist())\n#marida_test_df_invalid.to_csv('/kaggle/working/marida_test_df_invalid.csv')\nmarida_test_df_invalid =pd.read_csv('/kaggle/working/marida_test_df_invalid_info.csv')\nmarida_test_df_F = marida_test_df.drop(marida_test_df_invalid[marida_test_df_invalid['nan pixels'] > 0].index)\n\n# LR dataframe\n\nlr_df = create_LR_dataframe(LR_splits_path)\n#lr_df_invalid = compute_invalid_pixels(lr_df['image'].tolist(), lr_df['mask'].tolist())\n#lr_df_invalid.to_csv('/kaggle/working/litter_rows_df_invalid_info.csv')\nlr_df_invalid = pd.read_csv('/kaggle/working/litter_rows_df_invalid_info.csv')\nlr_df_F = lr_df.drop(lr_df_invalid[lr_df_invalid['high value pixels'] > 0].index)\n\n#LR val dataset\nlr_val_df = create_LR_dataframe(LR_splits_path, 'val')\n#lr_val_df_invalid = compute_invalid_pixels(lr_val_df['image'].tolist(), lr_val_df['mask'].tolist())\n#lr_val_df_invalid.to_csv('/kaggle/working/litter_rows_val_invalid_info.csv')\nlr_val_df_invalid = pd.read_csv('/kaggle/working/litter_rows_val_df_invalid_info.csv')\nlr_val_df_F= lr_val_df.drop(lr_val_df_invalid[lr_val_df_invalid['high value pixels']>0].index)\n\n\n#lr_test_df_invalid = compute_invalid_pixels(lr_test_df['image'].tolist(), lr_test_df['mask'].tolist())\n#lr_test_df_invalid.to_csv('/kaggle/working/litter_rows_df_invalid_info.csv')\n#lr_test_df_invalid = pd.read_csv('/kaggle/working/litter_rows_df_invalid_info.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:36.836699Z","iopub.execute_input":"2025-05-27T19:05:36.837047Z","iopub.status.idle":"2025-05-27T19:05:42.940872Z","shell.execute_reply.started":"2025-05-27T19:05:36.836995Z","shell.execute_reply":"2025-05-27T19:05:42.940257Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# lr valid = 79495168","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:42.941640Z","iopub.execute_input":"2025-05-27T19:05:42.941903Z","iopub.status.idle":"2025-05-27T19:05:42.945754Z","shell.execute_reply.started":"2025-05-27T19:05:42.941886Z","shell.execute_reply":"2025-05-27T19:05:42.944852Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"#lr_stats = compute_stats(lr_df_filt['image'].tolist())\n#np.savez(\"/kaggle/working/lr_stats.npz\", first=lr_stats['mean'], second=lr_stats['std'])\n#marida_stats = compute_stats(marida_df['image'].tolist())\n#np.savez(\"/kaggle/working/my_marida_stats.npz\", first=marida_stats['mean'], second=marida_stats['std'])\n#global_stats = compute_stats(marida_df['image'].tolist() + lr_df_filt['image'].to_list())\n#np.savez(\"/kaggle/working/global_stats.npz\", first=global_stats['mean'], second=global_stats['std'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:42.946554Z","iopub.execute_input":"2025-05-27T19:05:42.946786Z","iopub.status.idle":"2025-05-27T19:05:42.962976Z","shell.execute_reply.started":"2025-05-27T19:05:42.946763Z","shell.execute_reply":"2025-05-27T19:05:42.962345Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"global_stats = np.load('/kaggle/working/global_stats.npz')\nglobal_bands_mean = global_stats['first']\nglobal_bands_std = global_stats['second']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:42.963627Z","iopub.execute_input":"2025-05-27T19:05:42.963883Z","iopub.status.idle":"2025-05-27T19:05:42.982995Z","shell.execute_reply.started":"2025-05-27T19:05:42.963860Z","shell.execute_reply":"2025-05-27T19:05:42.982150Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# global_bands_mean =np.array([0.03721786, 0.03547978, 0.03033651, 0.01722546, 0.01574046,\n#         0.01738895, 0.01939084, 0.01724032, 0.01895351, 0.0109694 ,\n#         0.00784716])\n# global_bands_std = np.array([0.03185222, 0.03198375, 0.03251331, 0.03379553, 0.03407218,\n#         0.04551132, 0.05334419, 0.05064404, 0.0578197 , 0.03721222,\n#         0.02560836])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:42.983868Z","iopub.execute_input":"2025-05-27T19:05:42.984124Z","iopub.status.idle":"2025-05-27T19:05:42.997407Z","shell.execute_reply.started":"2025-05-27T19:05:42.984100Z","shell.execute_reply":"2025-05-27T19:05:42.996573Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"#computing_labeled_pixels_stats(lr_df_filt['mask'].tolist())\n#computing_labeled_pixels_stats(marida_df['mask'].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:42.998252Z","iopub.execute_input":"2025-05-27T19:05:42.998535Z","iopub.status.idle":"2025-05-27T19:05:43.013759Z","shell.execute_reply.started":"2025-05-27T19:05:42.998513Z","shell.execute_reply":"2025-05-27T19:05:43.013144Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"marida_classes_distr = np.array([0.00452, 0.00203, 0.00254, 0.00168, 0.00766, 0.15206, 0.20232,\n 0.35941, 0.00109, 0.20218, 0.03226, 0.00693, 0.01322, 0.01158, 0.00052])\nlr_debris_pixels = 92090\nmarida_pixels = 429412\nmarida_debris_pixels = np.sum(marida_classes_distr[[0,1,2,3,8]]) * marida_pixels\nprint(f'marida debris pixels {marida_debris_pixels}')\ntot_glob_pixels = (len(lr_df_F) + len(marida_df_F))*256**2\nmarida_debris_fraction = np.sum(marida_classes_distr[[0,1,2,3,8]])\n#debris_fraction = (lr_debris_pixels + marida_debris_pixels)/tot_glob_pixels\nprint(f'marida_debris_fraction : {marida_debris_fraction}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:43.014591Z","iopub.execute_input":"2025-05-27T19:05:43.014862Z","iopub.status.idle":"2025-05-27T19:05:43.030394Z","shell.execute_reply.started":"2025-05-27T19:05:43.014838Z","shell.execute_reply":"2025-05-27T19:05:43.029645Z"}},"outputs":[{"name":"stdout","text":"marida debris pixels 5092.826320000001\nmarida_debris_fraction : 0.011860000000000002\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Computing here the percentage of debris pixels across the two datasets\n# This will be used as class distribution to generate weights for the loss function\nLR_ratio = 15 # \n\n# For MARIDA the loss function uses only pixels in the 15 classes \n# The fraction of classes assimilated to marine debris is \nmarida_debrix_pixels_distr = np.sum(marida_classes_distr[[0,1,2,3,8]])\n# For LR the DataSet will sample backgroung pixels with a given ratio, stored in the variable LR_ratio\n# Then the effective ratio \neffective_ratio = (1/LR_ratio * len(lr_df_F) + 0.011860000000000002 * len(marida_df_F))/(len(lr_df_F) + len(marida_df_F))\n#print(f'effective global ratio {effective_ratio}')\nclass_distribution = np.array([1 - effective_ratio, effective_ratio])\nprint(f'class distribution {class_distribution}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:43.031163Z","iopub.execute_input":"2025-05-27T19:05:43.031713Z","iopub.status.idle":"2025-05-27T19:05:43.050875Z","shell.execute_reply.started":"2025-05-27T19:05:43.031690Z","shell.execute_reply":"2025-05-27T19:05:43.050152Z"}},"outputs":[{"name":"stdout","text":"class distribution [0.9532291 0.0467709]\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# MARIDA statistics\n\nclass_distr = np.array([0.00452, 0.00203, 0.00254, 0.00168, 0.00766, 0.15206, 0.20232,\n 0.35941, 0.00109, 0.20218, 0.03226, 0.00693, 0.01322, 0.01158, 0.00052])\n\nbands_mean = np.array([0.05197577, 0.04783991, 0.04056812, 0.03163572, 0.02972606, 0.03457443,\n 0.03875053, 0.03436435, 0.0392113,  0.02358126, 0.01588816]).astype(np.float32)\n\nbands_std = np.array([0.04725893, 0.04743808, 0.04699043, 0.04967381, 0.04946782, 0.06458357,\n 0.07594915, 0.07120246, 0.08251058, 0.05111466, 0.03524419]).astype(np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:43.051656Z","iopub.execute_input":"2025-05-27T19:05:43.051872Z","iopub.status.idle":"2025-05-27T19:05:43.067896Z","shell.execute_reply.started":"2025-05-27T19:05:43.051848Z","shell.execute_reply":"2025-05-27T19:05:43.067138Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Other code references  \n# https://github.com/MarcCoru/marinedebrisdetector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:43.068649Z","iopub.execute_input":"2025-05-27T19:05:43.068912Z","iopub.status.idle":"2025-05-27T19:05:43.085158Z","shell.execute_reply.started":"2025-05-27T19:05:43.068894Z","shell.execute_reply":"2025-05-27T19:05:43.084347Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# MARIDA CLASSES\n# {\n#  1: \"Marine Debris\",\n#  2: \"Dense Sargassum\", \n#  3: \"Sparse Sargassum\", \n#  4: \"Natural Organic Material\", \n#  5: \"Ship\", \n#  6: \"Clouds\", \n#  7: \"Marine Water\", \n#  8: \"Sediment-Laden Water\", \n#  9: \"Foam\", \n#  10: \"Turbid Water\", \n#  11: \"Shallow Water\", \n#  12: \"Waves\", \n#  13: \"Cloud Shadows\", \n#  14: \"Wakes\", \n#  15: \"Mixed Water\"\n# }\n\n\n# From marinedebrisdetector \n# DEBRIS_CLASSES = [1,2,3,4,9]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:43.086111Z","iopub.execute_input":"2025-05-27T19:05:43.086413Z","iopub.status.idle":"2025-05-27T19:05:43.105245Z","shell.execute_reply.started":"2025-05-27T19:05:43.086390Z","shell.execute_reply":"2025-05-27T19:05:43.104575Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# https://drive.google.com/drive/folders/1rntiw5BvOs80eIbpOu7dk9g1BfOVw61-?usp=drive_link","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:43.106175Z","iopub.execute_input":"2025-05-27T19:05:43.106401Z","iopub.status.idle":"2025-05-27T19:05:43.122473Z","shell.execute_reply.started":"2025-05-27T19:05:43.106384Z","shell.execute_reply":"2025-05-27T19:05:43.121673Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"\nclass RandomRotationTransform:\n    \"\"\"Rotate by one of the given angles.\"\"\"\n\n    def __init__(self, angles):\n        self.angles = angles\n\n    def __call__(self, x):\n        angle = random.choice(self.angles)\n        return vF.rotate(x, angle)\n    \ndef gen_weights(class_distribution, c = 1.02):\n    return 1/torch.log(c + class_distribution)\n    \ntransformTrain = transforms.Compose([transforms.ToTensor(),\n                                    RandomRotationTransform([-90, 0, 90, 180]),\n                                    transforms.RandomHorizontalFlip()])\n    \ntransformTest = transforms.Compose([transforms.ToTensor()])\n    \nstandardization = transforms.Normalize(global_bands_mean, global_bands_std) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:43.123398Z","iopub.execute_input":"2025-05-27T19:05:43.124120Z","iopub.status.idle":"2025-05-27T19:05:43.139279Z","shell.execute_reply.started":"2025-05-27T19:05:43.124101Z","shell.execute_reply":"2025-05-27T19:05:43.138530Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"def gen_weights(class_distribution, c = 1.02):\n    return 1/torch.log(c + class_distribution)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:43.140130Z","iopub.execute_input":"2025-05-27T19:05:43.140438Z","iopub.status.idle":"2025-05-27T19:05:43.154886Z","shell.execute_reply.started":"2025-05-27T19:05:43.140419Z","shell.execute_reply":"2025-05-27T19:05:43.154075Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"import os\nimport argparse\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom torchvision import transforms\n# model import UNet, AttentionUNet, ResidualAttentionUNet  # From original script\n#f#rom dataloader import bands_mean, bands_std, RandomRotationTransform, class_distr, gen_weights\n#from metrics import Evaluation\n#from customLosses import FocalLoss\nimport pandas as pd\nfrom torch.utils.data import Dataset\n\nclass MergedSegmentationDataset_B(Dataset):\n    \"\"\"\n    df_dataset1 : MARIDA dataset\n    df_dataset2 : LR dataset\n    \"\"\"\n    def __init__(self, df_dataset1, df_dataset2, bands_mean, bands_std, selected_bands, transform=None, standardization=None):\n        \"\"\"\n        df_dataset1 : MARIDA\n        df_dataset2 : Litter Windrows\n        \"\"\"\n        self.bands_mean = bands_mean[selected_bands]\n        self.bands_std = bands_std[selected_bands]\n        self.transform = transform\n        self.standardization = standardization\n        self.image_paths = []\n        self.mask_paths = []\n        self.dataset_ids = []\n        self.image_paths = df_dataset1['image'].tolist() + df_dataset2['image'].tolist() \n        self.mask_paths =  df_dataset1['mask'].tolist() + df_dataset2['mask'].tolist() \n        self.dataset_ids = [0] * len(df_dataset1['image']) + [1] * len(df_dataset2['image'])\n        # Generate shuffled indices\n        indices = np.random.permutation(len(self.image_paths))\n        self.image_paths = np.array(self.image_paths)[indices]\n        self.mask_paths = np.array(self.mask_paths)[indices]\n        self.dataset_ids = np.array(self.dataset_ids)[indices]        \n        #print(self.dataset_ids)\n        if self.transform is None:\n            self.transform = transforms.Compose([transforms.ToTensor()])\n        ## preloading images in memory \n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        #print(f'idx {idx}') \n        max_seed = 2**32 - 1  # NumPy seed limit\n        #index_seed_seed = (42 + idx) % max_seed\n        #np.random.seed(index_seed_seed)\n        # Load Classsification Mask np.random.seed(self.seed + index)  # Deterministic per item\n        dataset_id = self.dataset_ids[idx]\n        # Open t#he GeoTIFF image file\n        #print(f'image path {self.image_paths[idx]}')\n        #print(f'mask path {self.mask_paths[idx]}')\n        with rasterio.open(self.image_paths[idx]) as src:\n            #print(f#\"Number of bands: {dataset.count}\")  # Check the number of bands\n            # Read all bands as a NumPy array\n            image = src.read()\n            # Keep the bands in selecred_bands\n            image = image[selected_bands, :, :]\n            invalid_mask = get_invalid_mask(image, src.nodata)\n            with rasterio.open(self.mask_paths[idx]) as src_mask:\n                mask = src_mask.read().astype(int)\n            debris_before_invalid = np.sum(mask)\n            invalid_pixels = np.sum(np.any(invalid_mask, axis=0))\n            mask[np.any(invalid_mask.astype(bool), axis=0, keepdims=True)] = 0 #I guess it makes sense not to feed invalid pixels to the loss function\n            #print(f'before inputing 2')\n            image[invalid_mask.astype(bool)] = np.tile(self.bands_mean[:, np.newaxis, np.newaxis], (1, 256, 256))[invalid_mask.astype(bool)]\n            #print(f'after inputing')\n            ## Since the model sees unvalid pixels anyway, it's better (?) to replace those with mean values ? \n            #print(f'mask type before transh {type(mask)} - {mask.dtype}')\n            #print(f'image type before transh {type(image)} - {image.dtype}')\n            #############\n            debris_after_invalid = np.sum(mask)\n            #############\n            if self.transform is not None:\n                # applying the same rotation on the image-mask pair\n                #print(f'transform - image shape {image.shape}')\n                #print(f'transform - mask shape {mask.shape}')\n                stack = np.concatenate([image, mask], axis=0).astype(np.float32) \n                stack = np.transpose(stack,(1, 2, 0)) #to channel last\n                #print(f'stack shape before transfrom {stack.shape}')\n                stack = self.transform(stack) #expects channel last, returns channel first\n               \n                #print(f'stack shape after transfrom {stack.shape}')\n                image = stack[:-1,:,:]\n                mask = stack[-1,:,:].long()\n                #print(f'image type {image.dtype}')\n                #print(f'image shape after transform {image.shape}')\n                #print(f'mask shape after transform {mask.shape}')\n\n                   \n            \n            if self.standardization is not None:\n                image = self.standardization(image)\n                \n            #mask = mask - 1 Moved to collate function\n            if isinstance(mask, np.ndarray):\n                mask = torch.from_numpy(mask).to(torch.long)\n            else:\n                mask = mask.to(torch.long)\n            if isinstance(image, np.ndarray):\n                image = torch.from_numpy(image).to(torch.float32)\n            else:\n                im = image.to(torch.float32)\n            if torch.sum(mask) == 0 :\n                print(f'{self.mask_paths[idx]} has no debris pixels')\n                print(f'debris pixels before invalid mask : {debris_before_invalid}')\n                print(f'debris pixels after invalid mask : {debris_after_invalid}')\n                print(f'invalid pixels : {invalid_pixels}')\n           \n        ## Add logic for transform\n\n            return image, mask, dataset_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:43.155765Z","iopub.execute_input":"2025-05-27T19:05:43.156103Z","iopub.status.idle":"2025-05-27T19:05:48.441877Z","shell.execute_reply.started":"2025-05-27T19:05:43.156084Z","shell.execute_reply":"2025-05-27T19:05:48.440992Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"def conv3x3(in_channels, out_channels, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, channels, ratio=16):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.mlp = nn.Sequential(nn.Conv2d(channels, channels // 16, 1, bias=False),\n                               nn.ReLU(),\n                               nn.Conv2d(channels // 16, channels, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.mlp(self.avg_pool(x))\n        max_out = self.mlp(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, inputChannel, outputChannel, stride=1, downsample=None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = conv3x3(inputChannel, outputChannel, stride)\n        self.bn1 = nn.BatchNorm2d(outputChannel)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(outputChannel, outputChannel)\n        self.bn2 = nn.BatchNorm2d(outputChannel)\n        self.downsample = downsample\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n        \n    # def forward(self, x):\n    \n    #     residual = x\n    #     out = self.conv1(x)\n    #     out = self.bn1(out)\n    #     out = self.relu(out)\n    #     out = self.conv2(out)\n    #     out = self.bn2(out)\n    #     if self.downsample:\n    #         residual = self.downsample(x)\n    #     out += residual\n    #     out = self.relu(out)\n    #     caOutput = self.ca(out)\n    #     out = caOutput * out\n    #     saOutput = self.sa(out)\n    #     out = saOutput * out\n    #     return out, saOutput\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.bn2(out)\n        out = self.relu(out)\n        caOutput = self.ca(out)\n        out = caOutput * out\n        saOutput = self.sa(out)\n        out = saOutput * out\n        return out, saOutput\n\n\nclass DownSampleWithAttention(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.AvgPool2d(2)\n        )\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n    \n    def forward(self,x):\n        x = self.convolution(x)\n        caOutput = self.ca(x)\n        x = caOutput * x\n        saOutput = self.sa(x)\n        x = saOutput * x\n        return x, saOutput\n\n    \nclass UpSampleWithAttention(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2)\n        )\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n    \n    def forward(self, x):\n        x = self.upsample(x)\n        x = self.convolution(x)\n        caOutput = self.ca(x)\n        x = caOutput * x\n        saOutput = self.sa(x)\n        x = saOutput * x\n        return x, saOutput\n\nclass ResidualAttentionUNet(nn.Module):\n  def __init__(self, inputChannel, outputChannel):\n    super().__init__()\n    self.downsample1 = DownSampleWithAttention(inputChannel, 32)\n    self.downsample2 = DownSampleWithAttention(32, 64)\n    self.downsample3 = DownSampleWithAttention(64, 128)\n    self.downsample4 = DownSampleWithAttention(128, 256)\n    self.downsample5 = DownSampleWithAttention(256, 512)\n\n    self.residualBlock1 = ResidualBlock(512, 512)\n    self.residualBlock2 = ResidualBlock(512, 512)\n    self.residualBlock3 = ResidualBlock(512, 512)\n\n    self.upsample1 = UpSampleWithAttention(512, 256)\n    self.upsample2 = UpSampleWithAttention(512, 128)\n    self.upsample3 = UpSampleWithAttention(256, 64)\n    self.upsample4 = UpSampleWithAttention(128, 32)\n    self.upsample5 = UpSampleWithAttention(64, 32)\n    self.classification = nn.Sequential(\n            nn.Conv2d(32, outputChannel, kernel_size=1),\n        )\n\n  def forward(self, x):\n    scale128, sa128down = self.downsample1(x)\n    scale64, sa64down = self.downsample2(scale128)\n    scale32, sa32down = self.downsample3(scale64)\n    scale16, sa64down = self.downsample4(scale32)\n    scale8, sa8down = self.downsample5(scale16)\n    scale8, sa8down = self.residualBlock1(scale8)\n    scale8, sa8down = self.residualBlock2(scale8)\n    scale8, sa8down = self.residualBlock3(scale8)\n    upscale16, sa16up = self.upsample1(scale8)\n    upscale16 = torch.cat([upscale16, scale16], dim=1)\n    upscale32, sa32up = self.upsample2(upscale16)\n    upscale32 = torch.cat([upscale32, scale32], dim=1)\n    upscale64, sa64up = self.upsample3(upscale32)\n    upscale64 = torch.cat([upscale64, scale64], dim=1)\n    upscale128, sa128up = self.upsample4(upscale64)\n    upscale128 = torch.cat([upscale128, scale128], dim=1)\n    upscale256, sa256up = self.upsample5(upscale128)\n    finaloutput = self.classification(upscale256)\n    return finaloutput","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:48.442822Z","iopub.execute_input":"2025-05-27T19:05:48.443752Z","iopub.status.idle":"2025-05-27T19:05:48.473563Z","shell.execute_reply.started":"2025-05-27T19:05:48.443720Z","shell.execute_reply":"2025-05-27T19:05:48.472481Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def Evaluation(y_predicted, y_true):\n\n    micro_prec = precision_score(y_true, y_predicted, average='micro')\n    macro_prec = precision_score(y_true, y_predicted, average='macro')\n    weight_prec = precision_score(y_true, y_predicted, average='weighted')\n    \n    micro_rec = recall_score(y_true, y_predicted, average='micro')\n    macro_rec = recall_score(y_true, y_predicted, average='macro')\n    weight_rec = recall_score(y_true, y_predicted, average='weighted')\n        \n    macro_f1 = f1_score(y_true, y_predicted, average=\"macro\")\n    micro_f1 = f1_score(y_true, y_predicted, average=\"micro\")\n    weight_f1 = f1_score(y_true, y_predicted, average=\"weighted\")\n        \n    subset_acc = accuracy_score(y_true, y_predicted)\n    \n    iou_acc = jaccard_score(y_true, y_predicted, average='macro')\n\n    # Debris-specific metrics\n    debris_class = 1\n    debris_prec = precision_score(y_true, y_predicted, labels=[debris_class], average='macro')\n    debris_rec = recall_score(y_true, y_predicted, labels=[debris_class], average='macro')\n    debris_f1 = f1_score(y_true, y_predicted, labels=[debris_class], average='macro')\n    debris_iou = jaccard_score(y_true, y_predicted, labels=[debris_class], average='macro')\n\n    info = {\n            \"macroPrec\" : macro_prec,\n            \"microPrec\" : micro_prec,\n            \"weightPrec\" : weight_prec,\n            \"macroRec\" : macro_rec,\n            \"microRec\" : micro_rec,\n            \"weightRec\" : weight_rec,\n            \"macroF1\" : macro_f1,\n            \"microF1\" : micro_f1,\n            \"weightF1\" : weight_f1,\n            \"subsetAcc\" : subset_acc,\n            \"IoU\": iou_acc,\n            \"debris Prec\" : debris_prec,\n            \"debris Rec\" : debris_rec,\n            \"debris F1\" : debris_f1,\n            \"debris IoU\" : debris_iou\n            }\n    \n    return info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:48.474669Z","iopub.execute_input":"2025-05-27T19:05:48.475188Z","iopub.status.idle":"2025-05-27T19:05:48.502361Z","shell.execute_reply.started":"2025-05-27T19:05:48.475154Z","shell.execute_reply":"2025-05-27T19:05:48.501094Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"selected_bands = np.array([ 4, 6, 8, 11]) - 1 #bands conted from 0\n\ntransformTrain = transforms.Compose([transforms.ToTensor(),\n                                    RandomRotationTransform([-90, 0, 90, 180]),\n                                    transforms.RandomHorizontalFlip()])\n    \ntransformTest = transforms.Compose([transforms.ToTensor()])\n    \nstandardization = transforms.Normalize(global_bands_mean[selected_bands].tolist(), global_bands_std[selected_bands].tolist())\nmerged_ds = MergedSegmentationDataset_B(marida_df_F, lr_df_F, global_bands_mean, global_bands_std, selected_bands, transform=transformTrain, standardization= standardization)\nval_ds = MergedSegmentationDataset_B(marida_val_df_F, lr_val_df_F, global_bands_mean, global_bands_std,selected_bands, transform=transformTest, standardization= standardization )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:48.503498Z","iopub.execute_input":"2025-05-27T19:05:48.503838Z","iopub.status.idle":"2025-05-27T19:05:48.529377Z","shell.execute_reply.started":"2025-05-27T19:05:48.503804Z","shell.execute_reply":"2025-05-27T19:05:48.528366Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"\ntrainLoader = DataLoader(merged_ds,\n                        batch_size=batch_size, \n                        shuffle=True,  \n                        #num_workers=2, \n                        #pin_memory=True,\n                        #prefetch_factor=2,\n                        collate_fn=custom_collate_fn\n                        # worker_init_fn=worker_init_fn,\n                        # generator=torch.Generator().manual_seed(seed) \n                        )\n\n\ntestLoader = DataLoader(val_ds, \n                        batch_size=batch_size, \n                        shuffle=False,\n                        collate_fn=custom_collate_fn\n                        # worker_init_fn=worker_init_fn,\n                        # generator=torch.Generator().manual_seed(seed) \n                        )\n                        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:48.530594Z","iopub.execute_input":"2025-05-27T19:05:48.530899Z","iopub.status.idle":"2025-05-27T19:05:48.540776Z","shell.execute_reply.started":"2025-05-27T19:05:48.530874Z","shell.execute_reply":"2025-05-27T19:05:48.540062Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"model = ResidualAttentionUNet(len(selected_bands), 2).to(device)\nweight = gen_weights(torch.from_numpy(class_distribution), c = 1.03).to(device)\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean', weight=weight.to(torch.float32))\n#optimizer = torch.optim.Adam(model.parameters(), lr=8e-4, weight_decay=1e-2)\noptimizer = torch.optim.AdamW(model.parameters(), lr=8e-4, weight_decay=1e-4)\n\n\n# assuming about 40 reductions => .9 ** 40 = 1e-2, starting from 8e-4 ending with 8e-6\n#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=5)\n#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3) \nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n#scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:48.541850Z","iopub.execute_input":"2025-05-27T19:05:48.542229Z","iopub.status.idle":"2025-05-27T19:05:49.024264Z","shell.execute_reply.started":"2025-05-27T19:05:48.542201Z","shell.execute_reply":"2025-05-27T19:05:49.023496Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"best_metric = -float('inf')  # Initialize to negative infinity (for maximization, e.g., accuracy)\nbest_model_path = '/kaggle/working/best_model.pth'\noutput_classes = 2\nmetrics_history = []\npatience = 10  # Number of epochs to wait for improvement\nepochs_no_improve = 0  # Counter for epochs without improvement\nepochs = 60\nfor epoch in range(1, epochs+1):\n    model.train()\n    pb = tqdm(trainLoader, desc=f\"epoch {epoch}/{epochs}: \")\n    yTrue = []\n    yPredicted = []\n\n    bg_yTrue = []\n    bg_yPredicted = []\n    for image, target, _ in pb:\n        image, target = image.to(device), target.to(device)\n        optimizer.zero_grad()\n\n        logits = model(image)\n        # print(f'logits shape : {logits.shape}')\n        # print(f'target shape : {target.shape}')\n        # print(f'image dtype {image.dtype}')\n        # print(f'logits dtype {logits.dtype}')\n        # print(f'target dtype {target.dtype}')\n        loss = criterion(logits, target)\n\n        loss.backward()\n        optimizer.step()\n        pb.set_postfix(loss=loss.item())\n\n        if epoch % 10 == 0:\n            with torch.no_grad():\n                logits = logits.detach()\n                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n                logits = logits.reshape((-1,output_classes))\n                target = target.reshape(-1)\n                ###################################################################################\n                mask = target != -1\n                ###################################################################################\n                \n                # bg_logits = logits[~mask]\n                # bg_target = target[~mask]\n    \n                # only considering annotated pixels\n                logits = logits[mask]\n                target = target[mask]\n    \n                probs = F.softmax(logits, dim=1).cpu().numpy()\n                target = target.cpu().numpy()\n                yPredicted += probs.argmax(1).tolist()\n                yTrue += target.tolist()\n        \n                \n                # bg_probs = torch.nn.functional.softmax(bg_logits, dim=1).cpu().numpy()\n                # bg_target = bg_target.cpu().numpy()\n                \n                # bg_yPredicted += bg_probs.argmax(1).tolist()\n                # bg_yTrue += bg_target.tolist()\n\n\n    if epoch % 10 == 0:\n        yPredicted = np.asarray(yPredicted)\n        yTrue = np.asarray(yTrue)\n        acc = Evaluation(yPredicted, yTrue)\n        print(acc)\n    \n        # bg_yPredicted = np.asarray(bg_yPredicted)\n        # bg_yTrue = np.asarray(bg_yTrue)\n        # bg_acc = Evaluation(bg_yPredicted, bg_yTrue)\n        # print(\"background:\", bg_acc)\n\n\n    model.eval()\n    yTrue = []\n    yPredicted = []\n    testLossF = []\n    valPrecHistory = []\n    # bg_yTrue = []\n    # bg_yPredicted = []\n    iters = len(testLoader)\n    with torch.no_grad():\n        for i, (image, target, _) in enumerate(testLoader):\n\n            image, target = image.to(device), target.to(device)\n            logits = model(image)\n            # print(f'image dtype {image.dtype}')\n            # print(f'logits dtype {logits.dtype}')\n            # print(f'target dtype {target.dtype}')\n            # print(f'test - target shape {target.shape}')\n            # print(f'test - logit shape {logits.shape}')\n            loss = criterion(logits, target)\n\n            logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n            logits = logits.reshape((-1,output_classes))\n            target = target.reshape(-1)\n            ###################################################################################\n            mask = target != -1\n            ###################################################################################\n            \n            # bg_logits = logits[~mask]\n            # bg_target = target[~mask]\n            \n            logits = logits[mask]\n            target = target[mask]\n            \n\n            probs = F.softmax(logits, dim=1).cpu().numpy()\n            target = target.cpu().numpy()\n            # testBatches += target.shape[0]\n            testLossF.append((loss.data*target.shape[0]).tolist())\n            yPredicted += probs.argmax(1).tolist()\n            yTrue += target.tolist()\n\n            #scheduler.step(epoch + i/iters)\n            # bg_probs = torch.nn.functional.softmax(bg_logits, dim=1).cpu().numpy()\n            # bg_target = bg_target.cpu().numpy()\n\n            # bg_yPredicted += bg_probs.argmax(1).tolist()\n            # bg_yTrue += bg_target.tolist()\n        \n        yPredicted = np.asarray(yPredicted)\n        yTrue = np.asarray(yTrue)\n        print('########### Validation Set Evaluation : #############')\n        acc = Evaluation(yPredicted, yTrue)\n        metrics_history.append(acc)\n        if acc['debris IoU'] > best_metric:\n            best_metric = acc['debris IoU']\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"Saved best model with validation metric: {best_metric}\")\n            epochs_no_improve = 0  # Reset counter\n        else:\n            epochs_no_improve += 1\n            print(f\"No improvement for {epochs_no_improve}/{patience} epochs\")\n        # bg_yPredicted = np.asarray(bg_yPredicted)\n        # bg_yTrue = np.asarray(bg_yTrue)\n        # bg_acc = Evaluation(bg_yPredicted, bg_yTrue)\n        print(acc)\n        # Early stopping check\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping triggered at epoch {epoch}\")\n            break\n        # print(\"background:\", bg_acc)\n    #scheduler.step(sum(testLossF) / len(testLoader.dataset))\n    scheduler.step(acc['debris Prec'])\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T19:05:49.025185Z","iopub.execute_input":"2025-05-27T19:05:49.025520Z","iopub.status.idle":"2025-05-27T21:01:49.573031Z","shell.execute_reply.started":"2025-05-27T19:05:49.025494Z","shell.execute_reply":"2025-05-27T21:01:49.572018Z"}},"outputs":[{"name":"stderr","text":"epoch 1/60: 100%|██████████| 120/120 [02:49<00:00,  1.41s/it, loss=0.193]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.21912623130244435\n{'macroPrec': 0.6096942769521176, 'microPrec': 0.8729810592947925, 'weightPrec': 0.9692367106139109, 'macroRec': 0.9138776743428852, 'microRec': 0.8729810592947925, 'weightRec': 0.8729810592947925, 'macroF1': 0.6444905264883446, 'microF1': 0.8729810592947925, 'weightF1': 0.9082933158337974, 'subsetAcc': 0.8729810592947925, 'IoU': 0.5437062676620938, 'debris Prec': 0.22124844596565008, 'debris Rec': 0.9580619433736541, 'debris F1': 0.35948079153106643, 'debris IoU': 0.21912623130244435}\n","output_type":"stream"},{"name":"stderr","text":"epoch 2/60: 100%|██████████| 120/120 [01:36<00:00,  1.24it/s, loss=0.234] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.5669199533630844\n{'macroPrec': 0.7934129844952229, 'microPrec': 0.9733643242173977, 'weightPrec': 0.9823294906358379, 'macroRec': 0.9559773316474626, 'microRec': 0.9733643242173977, 'weightRec': 0.9733643242173977, 'macroF1': 0.8548092834170363, 'microF1': 0.9733643242173977, 'weightF1': 0.9762457509463501, 'subsetAcc': 0.9733643242173977, 'IoU': 0.769661007120747, 'debris Prec': 0.5893095954530257, 'debris Rec': 0.9371926093313837, 'debris F1': 0.7236106122030072, 'debris IoU': 0.5669199533630844}\n","output_type":"stream"},{"name":"stderr","text":"epoch 3/60: 100%|██████████| 120/120 [01:34<00:00,  1.27it/s, loss=0.107] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6022806406685237\n{'macroPrec': 0.8162734349755896, 'microPrec': 0.9774046783047327, 'weightPrec': 0.9834072953099671, 'macroRec': 0.9496734285439312, 'microRec': 0.9774046783047327, 'weightRec': 0.9774046783047327, 'macroF1': 0.8699714127496934, 'microF1': 0.9774046783047327, 'weightF1': 0.9793691903395225, 'subsetAcc': 0.9774046783047327, 'IoU': 0.7894423926263798, 'debris Prec': 0.6357037853730246, 'debris Rec': 0.9197128804998006, 'debris F1': 0.7517792144292932, 'debris IoU': 0.6022806406685237}\n","output_type":"stream"},{"name":"stderr","text":"epoch 4/60: 100%|██████████| 120/120 [01:35<00:00,  1.26it/s, loss=0.201] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.6641259114361722, 'microPrec': 0.9264477523366796, 'weightPrec': 0.9731115816793634, 'macroRec': 0.9381617808684132, 'microRec': 0.9264477523366796, 'weightRec': 0.9264477523366796, 'macroF1': 0.7253241238736412, 'microF1': 0.9264477523366796, 'weightF1': 0.9428753302913128, 'subsetAcc': 0.9264477523366796, 'IoU': 0.6242515292978913, 'debris Prec': 0.3303010712966383, 'debris Rec': 0.9508174930214011, 'debris F1': 0.4902841084341478, 'debris IoU': 0.32475256515027695}\n","output_type":"stream"},{"name":"stderr","text":"epoch 5/60: 100%|██████████| 120/120 [01:35<00:00,  1.26it/s, loss=0.072] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6308586426696663\n{'macroPrec': 0.8386979864049179, 'microPrec': 0.9805251965778151, 'weightPrec': 0.9841816429038773, 'macroRec': 0.9392178948235483, 'microRec': 0.9805251965778151, 'weightRec': 0.9805251965778151, 'macroF1': 0.8817385058807798, 'microF1': 0.9805251965778151, 'weightF1': 0.9817824000955491, 'subsetAcc': 0.9805251965778151, 'IoU': 0.8053566796323572, 'debris Prec': 0.6815189873417722, 'debris Rec': 0.8945899242323541, 'debris F1': 0.773652143924589, 'debris IoU': 0.6308586426696663}\n","output_type":"stream"},{"name":"stderr","text":"epoch 6/60: 100%|██████████| 120/120 [01:34<00:00,  1.26it/s, loss=0.334] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8097131887244808, 'microPrec': 0.9762796103061174, 'weightPrec': 0.9829445625563542, 'macroRec': 0.9494725251147184, 'microRec': 0.9762796103061174, 'weightRec': 0.9762796103061174, 'macroF1': 0.865166638731274, 'microF1': 0.9762796103061174, 'weightF1': 0.9784590318913194, 'subsetAcc': 0.9762796103061174, 'IoU': 0.7831165776236675, 'debris Prec': 0.6225558502269969, 'debris Rec': 0.9205104346670211, 'debris F1': 0.7427667390663126, 'debris IoU': 0.5907946935119225}\n","output_type":"stream"},{"name":"stderr","text":"epoch 7/60: 100%|██████████| 120/120 [01:34<00:00,  1.27it/s, loss=0.15]  \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8307743104577261, 'microPrec': 0.9797586667326047, 'weightPrec': 0.9845079116851432, 'macroRec': 0.9510875874607485, 'microRec': 0.9797586667326047, 'weightRec': 0.9797586667326047, 'macroF1': 0.8806110397233687, 'microF1': 0.9797586667326047, 'weightF1': 0.9813141620557596, 'subsetAcc': 0.9797586667326047, 'IoU': 0.8037285037852215, 'debris Prec': 0.6646821586326099, 'debris Rec': 0.9201116575834108, 'debris F1': 0.7718124547025701, 'debris IoU': 0.6284157966409442}\n","output_type":"stream"},{"name":"stderr","text":"epoch 8/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.133] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8383850193143692, 'microPrec': 0.9803446911626527, 'weightPrec': 0.9838713932996622, 'macroRec': 0.9352904772724622, 'microRec': 0.9803446911626527, 'weightRec': 0.9803446911626527, 'macroF1': 0.8800926420041703, 'microF1': 0.9803446911626527, 'weightF1': 0.9815746928312492, 'subsetAcc': 0.9803446911626527, 'IoU': 0.8031444595449927, 'debris Prec': 0.681203084307818, 'debris Rec': 0.8866143825601489, 'debris F1': 0.7704525109012678, 'debris IoU': 0.6266146836394382}\n","output_type":"stream"},{"name":"stderr","text":"epoch 9/60: 100%|██████████| 120/120 [01:34<00:00,  1.28it/s, loss=0.0961]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6494940202391905\n{'macroPrec': 0.8379878051834317, 'microPrec': 0.9811582018693438, 'weightPrec': 0.9857107104587521, 'macroRec': 0.9606318529934607, 'microRec': 0.9811582018693438, 'weightRec': 0.9811582018693438, 'macroF1': 0.8888245096078791, 'microF1': 0.9811582018693438, 'weightF1': 0.982603233172155, 'subsetAcc': 0.9811582018693438, 'IoU': 0.8149852883670972, 'debris Prec': 0.6783895454982224, 'debris Rec': 0.938455403429483, 'debris F1': 0.7875069715560514, 'debris IoU': 0.6494940202391905}\n","output_type":"stream"},{"name":"stderr","text":"epoch 10/60: 100%|██████████| 120/120 [01:34<00:00,  1.27it/s, loss=0.0635]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8608294099443128, 'microPrec': 0.9794086963833829, 'weightPrec': 0.9841105816569761, 'macroRec': 0.9730825817222302, 'microRec': 0.9794086963833829, 'weightRec': 0.9794086963833829, 'macroF1': 0.9082124310926507, 'microF1': 0.9794086963833829, 'weightF1': 0.9807927865065204, 'subsetAcc': 0.9794086963833829, 'IoU': 0.8419563940128865, 'debris Prec': 0.7235206633223139, 'debris Rec': 0.9660366487298468, 'debris F1': 0.827373504168062, 'debris IoU': 0.7055729229289407}\n########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.683944374209861\n{'macroPrec': 0.8578097422128214, 'microPrec': 0.9839276000197814, 'weightPrec': 0.9870628674240853, 'macroRec': 0.9603449041301788, 'microRec': 0.9839276000197814, 'weightRec': 0.9839276000197814, 'macroF1': 0.9019583178491379, 'microF1': 0.9839276000197814, 'weightF1': 0.9849339618840245, 'subsetAcc': 0.9839276000197814, 'IoU': 0.83364641101451, 'debris Prec': 0.7181660369651792, 'debris Rec': 0.9348664096769905, 'debris F1': 0.8123123123123124, 'debris IoU': 0.683944374209861}\n","output_type":"stream"},{"name":"stderr","text":"epoch 11/60: 100%|██████████| 120/120 [01:32<00:00,  1.29it/s, loss=0.0555]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7156726768377254\n{'macroPrec': 0.8781137210255228, 'microPrec': 0.9863137332476138, 'weightPrec': 0.9882599057643984, 'macroRec': 0.9573031329426251, 'microRec': 0.9863137332476138, 'weightRec': 0.9863137332476138, 'macroF1': 0.9135693007700751, 'microF1': 0.9863137332476138, 'weightF1': 0.9869621219862654, 'subsetAcc': 0.9863137332476138, 'IoU': 0.8507490527660385, 'debris Prec': 0.7591129515610527, 'debris Rec': 0.9259603881430281, 'debris F1': 0.8342764753435731, 'debris IoU': 0.7156726768377254}\n","output_type":"stream"},{"name":"stderr","text":"epoch 12/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.142] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7163124364259329\n{'macroPrec': 0.8910785139932154, 'microPrec': 0.9868972850007418, 'weightPrec': 0.9879149878931849, 'macroRec': 0.9399712677049141, 'microRec': 0.9868972850007418, 'weightRec': 0.9868972850007418, 'macroF1': 0.9139446295202356, 'microF1': 0.9868972850007418, 'weightF1': 0.9872826579945035, 'subsetAcc': 0.9868972850007418, 'IoU': 0.8513806965272054, 'debris Prec': 0.7864574149180039, 'debris Rec': 0.8892728964508839, 'debris F1': 0.8347110015908169, 'debris IoU': 0.7163124364259329}\n","output_type":"stream"},{"name":"stderr","text":"epoch 13/60: 100%|██████████| 120/120 [01:32<00:00,  1.29it/s, loss=0.0625]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8438267722802807, 'microPrec': 0.9818010978685525, 'weightPrec': 0.9856816352496909, 'macroRec': 0.9547679438594381, 'microRec': 0.9818010978685525, 'weightRec': 0.9818010978685525, 'macroF1': 0.8907333656226748, 'microF1': 0.9818010978685526, 'weightF1': 0.9830639816335275, 'subsetAcc': 0.9818010978685525, 'IoU': 0.8176924541254049, 'debris Prec': 0.6905682832490331, 'debris Rec': 0.9255616110594178, 'debris F1': 0.7909803476087699, 'debris IoU': 0.6542328290895424}\n","output_type":"stream"},{"name":"stderr","text":"epoch 14/60: 100%|██████████| 120/120 [01:33<00:00,  1.29it/s, loss=0.0911]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8555086091490348, 'microPrec': 0.9839078186044211, 'weightPrec': 0.9874306453056609, 'macroRec': 0.9675227762476832, 'microRec': 0.9839078186044211, 'weightRec': 0.9839078186044211, 'macroF1': 0.9030615349129931, 'microF1': 0.9839078186044211, 'weightF1': 0.9850018800830168, 'subsetAcc': 0.9839078186044211, 'IoU': 0.8352093398278984, 'debris Prec': 0.7129814408301736, 'debris Rec': 0.9498205503123753, 'debris F1': 0.8145340552864063, 'debris IoU': 0.6871003413625655}\n","output_type":"stream"},{"name":"stderr","text":"epoch 15/60: 100%|██████████| 120/120 [01:33<00:00,  1.28it/s, loss=0.125] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8611060557312122, 'microPrec': 0.984637258295831, 'weightPrec': 0.9877838301432019, 'macroRec': 0.9670390120175454, 'microRec': 0.984637258295831, 'weightRec': 0.984637258295831, 'macroF1': 0.9065681051158624, 'microF1': 0.984637258295831, 'weightF1': 0.9856190384162427, 'subsetAcc': 0.984637258295831, 'IoU': 0.8403310072772556, 'debris Prec': 0.7242447321655242, 'debris Rec': 0.9480260534361292, 'debris F1': 0.8211623154198209, 'debris IoU': 0.696586414025492}\n","output_type":"stream"},{"name":"stderr","text":"epoch 16/60: 100%|██████████| 120/120 [01:35<00:00,  1.25it/s, loss=0.0398]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7181218511400821\n{'macroPrec': 0.8817740141320678, 'microPrec': 0.9865807823549775, 'weightPrec': 0.9882805484315333, 'macroRec': 0.9540554021010931, 'microRec': 0.9865807823549775, 'weightRec': 0.9865807823549775, 'macroF1': 0.9144712486115496, 'microF1': 0.9865807823549775, 'weightF1': 0.987160818433115, 'subsetAcc': 0.9865807823549775, 'IoU': 0.8521138142472865, 'debris Prec': 0.76670548438973, 'debris Rec': 0.9189153263325801, 'debris F1': 0.8359382085310922, 'debris IoU': 0.7181218511400821}\n","output_type":"stream"},{"name":"stderr","text":"epoch 17/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.0356]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7264585598177771\n{'macroPrec': 0.8820197302862244, 'microPrec': 0.9869343751545423, 'weightPrec': 0.9887929981085568, 'macroRec': 0.960852123596752, 'microRec': 0.9869343751545423, 'weightRec': 0.9869343751545423, 'macroF1': 0.9173727319630749, 'microF1': 0.9869343751545423, 'weightF1': 0.9875451273940599, 'subsetAcc': 0.9869343751545423, 'IoU': 0.856461636519124, 'debris Prec': 0.7666630244755245, 'debris Rec': 0.9326731357171342, 'debris F1': 0.8415592203898051, 'debris IoU': 0.7264585598177771}\n","output_type":"stream"},{"name":"stderr","text":"epoch 18/60: 100%|██████████| 120/120 [01:34<00:00,  1.27it/s, loss=0.0423]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7373349466042401\n{'macroPrec': 0.8884554117724159, 'microPrec': 0.9876539241382721, 'weightPrec': 0.9892331873283381, 'macroRec': 0.9606826960286956, 'microRec': 0.9876539241382721, 'weightRec': 0.9876539241382721, 'macroF1': 0.9211878468864978, 'microF1': 0.9876539241382721, 'weightF1': 0.9881788235165065, 'subsetAcc': 0.9876539241382721, 'IoU': 0.8622728154604996, 'debris Prec': 0.779576172200901, 'debris Rec': 0.9315432673135717, 'debris F1': 0.8488115064345193, 'debris IoU': 0.7373349466042401}\n","output_type":"stream"},{"name":"stderr","text":"epoch 19/60: 100%|██████████| 120/120 [01:35<00:00,  1.26it/s, loss=0.0652]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8740721804667386, 'microPrec': 0.9864200583551753, 'weightPrec': 0.9889124237033574, 'macroRec': 0.9701053269414778, 'microRec': 0.9864200583551753, 'weightRec': 0.9864200583551753, 'macroF1': 0.9160547992974204, 'microF1': 0.9864200583551753, 'weightF1': 0.987191999830473, 'subsetAcc': 0.9864200583551753, 'IoU': 0.8544346260914506, 'debris Prec': 0.75, 'debris Rec': 0.9524790642031105, 'debris F1': 0.8391989225273759, 'debris IoU': 0.7229480906018262}\n","output_type":"stream"},{"name":"stderr","text":"epoch 20/60: 100%|██████████| 120/120 [01:33<00:00,  1.28it/s, loss=0.148] \n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8817828707608794, 'microPrec': 0.9833629834791314, 'weightPrec': 0.9866087108933622, 'macroRec': 0.9785587884635937, 'microRec': 0.9833629834791314, 'weightRec': 0.9833629834791314, 'macroF1': 0.923910767658281, 'microF1': 0.9833629834791314, 'weightF1': 0.9842978677887234, 'subsetAcc': 0.9833629834791314, 'IoU': 0.8658710681291006, 'debris Prec': 0.7650293996328079, 'debris Rec': 0.9732079470743777, 'debris F1': 0.8566525082188431, 'debris IoU': 0.7492494752267417}\n########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7388071424831125\n{'macroPrec': 0.8872507428061398, 'microPrec': 0.9876662875228722, 'weightPrec': 0.989365249795341, 'macroRec': 0.9636602165313253, 'microRec': 0.9876662875228722, 'weightRec': 0.9876662875228722, 'macroF1': 0.9216776575263488, 'microF1': 0.9876662875228722, 'weightF1': 0.9882198458310427, 'subsetAcc': 0.9876662875228722, 'IoU': 0.8630137948837288, 'debris Prec': 0.7769273127753304, 'debris Rec': 0.9377243121095308, 'debris F1': 0.8497861832199001, 'debris IoU': 0.7388071424831125}\n","output_type":"stream"},{"name":"stderr","text":"epoch 21/60: 100%|██████████| 120/120 [01:33<00:00,  1.29it/s, loss=0.0705]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7465922507244821\n{'macroPrec': 0.8960202950776093, 'microPrec': 0.9883240195836012, 'weightPrec': 0.9895503383532276, 'macroRec': 0.9577081701384246, 'microRec': 0.9883240195836012, 'weightRec': 0.9883240195836012, 'macroF1': 0.9244151495747863, 'microF1': 0.9883240195836012, 'weightF1': 0.988745754813818, 'subsetAcc': 0.9883240195836012, 'IoU': 0.8672501544730403, 'debris Prec': 0.7949714285714286, 'debris Rec': 0.9246311311976605, 'debris F1': 0.8549130461500646, 'debris IoU': 0.7465922507244821}\n","output_type":"stream"},{"name":"stderr","text":"epoch 22/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.0701]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8887365771637921, 'microPrec': 0.9878715197072351, 'weightPrec': 0.9895263625753601, 'macroRec': 0.964437691399367, 'microRec': 0.9878715197072351, 'weightRec': 0.9878715197072351, 'macroF1': 0.9228897980438887, 'microF1': 0.9878715197072351, 'weightF1': 0.9884093948353047, 'subsetAcc': 0.9878715197072351, 'IoU': 0.8648746034575612, 'debris Prec': 0.7798443622716486, 'debris Rec': 0.9391200319021666, 'debris F1': 0.8521031207598372, 'debris IoU': 0.7423167848699763}\n","output_type":"stream"},{"name":"stderr","text":"epoch 23/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0914]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8918565539557739, 'microPrec': 0.9879605360763563, 'weightPrec': 0.9893751401753613, 'macroRec': 0.959340402346353, 'microRec': 0.9879605360763563, 'weightRec': 0.9879605360763563, 'macroF1': 0.9226561669652198, 'microF1': 0.9879605360763563, 'weightF1': 0.9884376489925804, 'subsetAcc': 0.9879605360763563, 'IoU': 0.864531438363892, 'debris Prec': 0.7864985079668938, 'debris Rec': 0.928419513491958, 'debris F1': 0.8515865516505624, 'debris IoU': 0.7415330714513217}\n","output_type":"stream"},{"name":"stderr","text":"epoch 24/60: 100%|██████████| 120/120 [01:30<00:00,  1.33it/s, loss=0.0288]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7523279460558707\n{'macroPrec': 0.8958861178957778, 'microPrec': 0.9885564512140844, 'weightPrec': 0.9898884064471324, 'macroRec': 0.9624931841417639, 'microRec': 0.9885564512140844, 'weightRec': 0.9885564512140844, 'macroF1': 0.9263489744718033, 'microF1': 0.9885564512140844, 'weightF1': 0.9890003169151803, 'subsetAcc': 0.9885564512140844, 'IoU': 0.8702361419378191, 'debris Prec': 0.794327042603684, 'debris Rec': 0.9343347068988436, 'debris F1': 0.8586611287564133, 'debris IoU': 0.7523279460558707}\n","output_type":"stream"},{"name":"stderr","text":"epoch 25/60: 100%|██████████| 120/120 [01:30<00:00,  1.32it/s, loss=0.147] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8815257977553393, 'microPrec': 0.9871148805697048, 'weightPrec': 0.9891217704669948, 'macroRec': 0.9658338024170101, 'microRec': 0.9871148805697048, 'weightRec': 0.9871148805697048, 'macroF1': 0.9190552823933771, 'microF1': 0.9871148805697048, 'weightF1': 0.9877555827036169, 'subsetAcc': 0.9871148805697048, 'IoU': 0.8589983412247217, 'debris Prec': 0.7652802503101904, 'debris Rec': 0.9428419513491958, 'debris F1': 0.8448322067712831, 'debris IoU': 0.7313502087951745}\n","output_type":"stream"},{"name":"stderr","text":"epoch 26/60: 100%|██████████| 120/120 [01:34<00:00,  1.27it/s, loss=0.0222]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8875545287652322, 'microPrec': 0.9879209732456358, 'weightPrec': 0.9897129095372001, 'macroRec': 0.9681373144348187, 'microRec': 0.9879209732456358, 'weightRec': 0.9879209732456358, 'macroF1': 0.9236667563313649, 'microF1': 0.9879209732456358, 'weightF1': 0.9884894934901601, 'subsetAcc': 0.9879209732456358, 'IoU': 0.8660609503067555, 'debris Prec': 0.7771836979649736, 'debris Rec': 0.9467632593380301, 'debris F1': 0.853632958801498, 'debris IoU': 0.7446419236800836}\n","output_type":"stream"},{"name":"stderr","text":"epoch 27/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0486]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7536799745843482\n{'macroPrec': 0.8927191849360526, 'microPrec': 0.9884971069680035, 'weightPrec': 0.9900721142882056, 'macroRec': 0.9680850922119493, 'microRec': 0.9884971069680035, 'weightRec': 0.9884971069680035, 'macroF1': 0.9267720267858988, 'microF1': 0.9884971069680035, 'weightF1': 0.9890004830595506, 'subsetAcc': 0.9884971069680035, 'IoU': 0.8708787277902955, 'debris Prec': 0.787540112869315, 'debris Rec': 0.9460321680180779, 'debris F1': 0.8595410628019322, 'debris IoU': 0.7536799745843482}\n","output_type":"stream"},{"name":"stderr","text":"epoch 28/60: 100%|██████████| 120/120 [01:30<00:00,  1.32it/s, loss=0.0603]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.9223778561205576, 'microPrec': 0.9883438009989615, 'weightPrec': 0.9882248876574029, 'macroRec': 0.9132477858656565, 'microRec': 0.9883438009989615, 'weightRec': 0.9883438009989615, 'macroF1': 0.917758420217067, 'microF1': 0.9883438009989615, 'weightF1': 0.9882801233268367, 'subsetAcc': 0.9883438009989615, 'IoU': 0.8572211754193949, 'debris Prec': 0.8512374218112592, 'debris Rec': 0.8321148478000797, 'debris F1': 0.8415675203334005, 'debris IoU': 0.7264709295578508}\n","output_type":"stream"},{"name":"stderr","text":"epoch 29/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0704]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8894245848868098, 'microPrec': 0.988160822906879, 'weightPrec': 0.9898859561985154, 'macroRec': 0.9687091356988113, 'microRec': 0.988160822906879, 'weightRec': 0.988160822906879, 'macroF1': 0.9250341539878517, 'microF1': 0.988160822906879, 'weightF1': 0.9887075258442669, 'subsetAcc': 0.988160822906879, 'IoU': 0.8681749866034298, 'debris Prec': 0.7808871851040525, 'debris Rec': 0.9476937391997873, 'debris F1': 0.8562421185372004, 'debris IoU': 0.7486218302094818}\n","output_type":"stream"},{"name":"stderr","text":"epoch 30/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0398]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8867921636285276, 'microPrec': 0.9842606339788043, 'weightPrec': 0.987210720302796, 'macroRec': 0.9798933179316839, 'microRec': 0.9842606339788043, 'weightRec': 0.9842606339788043, 'macroF1': 0.9275994332250257, 'microF1': 0.9842606339788043, 'weightF1': 0.9851053353013619, 'subsetAcc': 0.9842606339788043, 'IoU': 0.8716511115176264, 'debris Prec': 0.7749474596645596, 'debris Rec': 0.97502906587923, 'debris F1': 0.8635502095862949, 'debris IoU': 0.7598665747229661}\n########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8839334632266471, 'microPrec': 0.9877157410612729, 'weightPrec': 0.9897776106598138, 'macroRec': 0.9725033566678886, 'microRec': 0.9877157410612729, 'weightRec': 0.9877157410612729, 'macroF1': 0.9231690822980556, 'microF1': 0.9877157410612729, 'weightF1': 0.9883506170947751, 'subsetAcc': 0.9877157410612729, 'IoU': 0.8652791473187311, 'debris Prec': 0.769580569227477, 'debris Rec': 0.9560680579556028, 'debris F1': 0.8527476436066156, 'debris IoU': 0.7432956130832429}\n","output_type":"stream"},{"name":"stderr","text":"epoch 31/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0853]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7548823370300244\n{'macroPrec': 0.8997276347186114, 'microPrec': 0.9887963008753277, 'weightPrec': 0.9899273881642124, 'macroRec': 0.9592952226856871, 'microRec': 0.9887963008753277, 'weightRec': 0.9887963008753277, 'macroF1': 0.9272432747808956, 'microF1': 0.9887963008753277, 'weightF1': 0.9891846673570662, 'subsetAcc': 0.9887963008753277, 'IoU': 0.8716391268519736, 'debris Prec': 0.8022767780141437, 'debris Rec': 0.9274225707829323, 'debris F1': 0.8603224513702642, 'debris IoU': 0.7548823370300244}\n","output_type":"stream"},{"name":"stderr","text":"epoch 32/60: 100%|██████████| 120/120 [01:30<00:00,  1.33it/s, loss=0.137] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.75792\n{'macroPrec': 0.8955427486572591, 'microPrec': 0.9887765194599674, 'weightPrec': 0.9902279299075267, 'macroRec': 0.9674954087611765, 'microRec': 0.9887765194599674, 'weightRec': 0.9887765194599674, 'macroF1': 0.9282208301978284, 'microF1': 0.9887765194599674, 'weightF1': 0.9892442272621558, 'subsetAcc': 0.9887765194599674, 'IoU': 0.8731438860713105, 'debris Prec': 0.793245883337985, 'debris Rec': 0.9445035225309052, 'debris F1': 0.8622917993992901, 'debris IoU': 0.75792}\n","output_type":"stream"},{"name":"stderr","text":"epoch 33/60: 100%|██████████| 120/120 [01:31<00:00,  1.32it/s, loss=0.0758]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7618559482060966\n{'macroPrec': 0.899741290167639, 'microPrec': 0.9890856040749716, 'weightPrec': 0.9903265511002065, 'macroRec': 0.9647806648102386, 'microRec': 0.9890856040749716, 'weightRec': 0.9890856040749716, 'macroF1': 0.92957330953914, 'microF1': 0.9890856040749716, 'weightF1': 0.989496051356553, 'subsetAcc': 0.9890856040749716, 'IoU': 0.8752733349674113, 'debris Prec': 0.8018739352640545, 'debris Rec': 0.9385218662767513, 'debris F1': 0.8648334149926508, 'debris IoU': 0.7618559482060966}\n","output_type":"stream"},{"name":"stderr","text":"epoch 34/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0655]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7640437217902006\n{'macroPrec': 0.9026113879998755, 'microPrec': 0.989271054843974, 'weightPrec': 0.9903715501343591, 'macroRec': 0.9626087141494964, 'microRec': 0.989271054843974, 'weightRec': 0.989271054843974, 'macroF1': 0.93032632294732, 'microF1': 0.989271054843974, 'weightF1': 0.9896429643924765, 'subsetAcc': 0.989271054843974, 'IoU': 0.8764643129277873, 'debris Prec': 0.807796239866613, 'debris Rec': 0.9338030041206965, 'debris F1': 0.866241252812972, 'debris IoU': 0.7640437217902006}\n","output_type":"stream"},{"name":"stderr","text":"epoch 35/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0363]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7689657058469617\n{'macroPrec': 0.9051486651686904, 'microPrec': 0.989555412689778, 'weightPrec': 0.9905824586783049, 'macroRec': 0.9630439128816031, 'microRec': 0.989555412689778, 'weightRec': 0.989555412689778, 'macroF1': 0.9319780120433621, 'microF1': 0.989555412689778, 'weightF1': 0.9899035900919745, 'subsetAcc': 0.989555412689778, 'IoU': 0.8790724763745941, 'debris Prec': 0.8128469010175763, 'debris Rec': 0.9344011697461119, 'debris F1': 0.8693958320450188, 'debris IoU': 0.7689657058469617}\n","output_type":"stream"},{"name":"stderr","text":"epoch 36/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.0301]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.9071132316912767, 'microPrec': 0.9895183225359775, 'weightPrec': 0.9904052505433517, 'macroRec': 0.9586798168734596, 'microRec': 0.9895183225359775, 'weightRec': 0.9895183225359775, 'macroF1': 0.931212434353178, 'microF1': 0.9895183225359775, 'weightF1': 0.989830416846607, 'subsetAcc': 0.9895183225359775, 'IoU': 0.8778725987758229, 'debris Prec': 0.8171254181583426, 'debris Rec': 0.9253622225176127, 'debris F1': 0.867882187938289, 'debris IoU': 0.7666005946481665}\n","output_type":"stream"},{"name":"stderr","text":"epoch 37/60: 100%|██████████| 120/120 [01:33<00:00,  1.29it/s, loss=0.058] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7711760098467048\n{'macroPrec': 0.9132537152340741, 'microPrec': 0.9898867513970625, 'weightPrec': 0.9905333496073407, 'macroRec': 0.9544304733730891, 'microRec': 0.9898867513970625, 'weightRec': 0.9898867513970625, 'macroF1': 0.9327720722637929, 'microF1': 0.9898867513970626, 'weightF1': 0.9901266942762258, 'subsetAcc': 0.9898867513970625, 'IoU': 0.880352952342433, 'debris Prec': 0.8297616181073922, 'debris Rec': 0.9161238867473083, 'debris F1': 0.8708067471097353, 'debris IoU': 0.7711760098467048}\n","output_type":"stream"},{"name":"stderr","text":"epoch 38/60: 100%|██████████| 120/120 [01:34<00:00,  1.27it/s, loss=0.0217]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8966562070412878, 'microPrec': 0.988825972998368, 'weightPrec': 0.9902059978559218, 'macroRec': 0.9661154093178903, 'microRec': 0.988825972998368, 'weightRec': 0.988825972998368, 'macroF1': 0.9283121613473089, 'microF1': 0.988825972998368, 'weightF1': 0.9892756325051826, 'subsetAcc': 0.988825972998368, 'IoU': 0.8732907613234342, 'debris Prec': 0.7955860055034537, 'debris Rec': 0.9415791572510966, 'debris F1': 0.8624478738623566, 'debris IoU': 0.7581611901958686}\n","output_type":"stream"},{"name":"stderr","text":"epoch 39/60: 100%|██████████| 120/120 [01:35<00:00,  1.26it/s, loss=0.0653]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.9030593603788643, 'microPrec': 0.9893922160130557, 'weightPrec': 0.9905051212858671, 'macroRec': 0.9640134227292625, 'microRec': 0.9893922160130557, 'weightRec': 0.9893922160130557, 'macroF1': 0.9311842855756747, 'microF1': 0.9893922160130557, 'weightF1': 0.9897649886475293, 'subsetAcc': 0.9893922160130557, 'IoU': 0.8778143813013953, 'debris Prec': 0.8085838879963277, 'debris Rec': 0.9365944437059683, 'debris F1': 0.867894315452362, 'debris IoU': 0.7666195190947667}\n","output_type":"stream"},{"name":"stderr","text":"epoch 40/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.0286]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8901834418345138, 'microPrec': 0.9848608195002483, 'weightPrec': 0.9876222998143702, 'macroRec': 0.9808326021202978, 'microRec': 0.9848608195002483, 'weightRec': 0.9848608195002483, 'macroF1': 0.9300952762507035, 'microF1': 0.9848608195002483, 'weightF1': 0.9856480198587585, 'subsetAcc': 0.9848608195002483, 'IoU': 0.8755981591710924, 'debris Prec': 0.7816574822283178, 'debris Rec': 0.9763460331505356, 'debris F1': 0.8682214516409417, 'debris IoU': 0.7671301535974131}\n########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.914370416012694, 'microPrec': 0.9896716285050196, 'weightPrec': 0.9901987203815765, 'macroRec': 0.9486960288212691, 'microRec': 0.9896716285050196, 'weightRec': 0.9896716285050196, 'macroF1': 0.9307860734047242, 'microF1': 0.9896716285050196, 'weightF1': 0.9898770026661003, 'subsetAcc': 0.9896716285050196, 'IoU': 0.8772255793881782, 'debris Prec': 0.8324463204257662, 'debris Rec': 0.904426425628074, 'debris F1': 0.8669448603191795, 'debris IoU': 0.76513916221535}\n","output_type":"stream"},{"name":"stderr","text":"epoch 41/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.101] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7745372658867469\n{'macroPrec': 0.90722666530067, 'microPrec': 0.9898496612432619, 'weightPrec': 0.9908400811041125, 'macroRec': 0.9645704566438571, 'microRec': 0.9898496612432619, 'weightRec': 0.9898496612432619, 'macroF1': 0.9338296438680733, 'microF1': 0.9898496612432619, 'weightF1': 0.9901834228856772, 'subsetAcc': 0.9898496612432619, 'IoU': 0.8820101001572862, 'debris Prec': 0.8168916179111394, 'debris Rec': 0.9372590721786521, 'debris F1': 0.8729456188678077, 'debris IoU': 0.7745372658867469}\n","output_type":"stream"},{"name":"stderr","text":"epoch 42/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.128] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.9084686629924681, 'microPrec': 0.9898175164433015, 'weightPrec': 0.9907183945485459, 'macroRec': 0.9616785051752115, 'microRec': 0.9898175164433015, 'weightRec': 0.9898175164433015, 'macroF1': 0.9332895479567315, 'microF1': 0.9898175164433015, 'weightF1': 0.9901287954750936, 'subsetAcc': 0.9898175164433015, 'IoU': 0.8811573594927713, 'debris Prec': 0.8196069255966308, 'debris Rec': 0.9312774159244982, 'debris F1': 0.8718810279385228, 'debris IoU': 0.7728626585769443}\n","output_type":"stream"},{"name":"stderr","text":"epoch 43/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0421]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8958406111567933, 'microPrec': 0.9890237871519707, 'weightPrec': 0.9905535536951818, 'macroRec': 0.9716811285266451, 'microRec': 0.9890237871519707, 'weightRec': 0.9890237871519707, 'macroF1': 0.9301147983859688, 'microF1': 0.9890237871519707, 'weightF1': 0.9895033979114262, 'subsetAcc': 0.9890237871519707, 'IoU': 0.876107049842737, 'debris Prec': 0.7935137528363495, 'debris Rec': 0.9529443041339891, 'debris F1': 0.8659519855050581, 'debris IoU': 0.7635937583213506}\n","output_type":"stream"},{"name":"stderr","text":"epoch 44/60: 100%|██████████| 120/120 [01:32<00:00,  1.29it/s, loss=0.0597]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.9021503255806052, 'microPrec': 0.9895875574897384, 'weightPrec': 0.99083804850726, 'macroRec': 0.969482015892009, 'microRec': 0.9895875574897384, 'weightRec': 0.9895875574897384, 'macroF1': 0.9329597118210191, 'microF1': 0.9895875574897384, 'weightF1': 0.9899896164280436, 'subsetAcc': 0.9895875574897384, 'IoU': 0.8806139989522115, 'debris Prec': 0.8063330506078598, 'debris Rec': 0.9477602020470557, 'debris F1': 0.8713452079068773, 'debris IoU': 0.7720210059011423}\n","output_type":"stream"},{"name":"stderr","text":"epoch 45/60: 100%|██████████| 120/120 [01:32<00:00,  1.29it/s, loss=0.0802]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.902629743119459, 'microPrec': 0.9893847979822956, 'weightPrec': 0.9905255023873182, 'macroRec': 0.9647124112380356, 'microRec': 0.9893847979822956, 'weightRec': 0.9893847979822956, 'macroF1': 0.9312315229566881, 'microF1': 0.9893847979822956, 'weightF1': 0.9897646169789512, 'subsetAcc': 0.9893847979822956, 'IoU': 0.8778872239017361, 'debris Prec': 0.8076680972818312, 'debris Rec': 0.9380566263458726, 'debris F1': 0.8679929891454753, 'debris IoU': 0.7667735100776878}\n","output_type":"stream"},{"name":"stderr","text":"epoch 46/60: 100%|██████████| 120/120 [01:32<00:00,  1.29it/s, loss=0.446] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7751937984496124\n{'macroPrec': 0.9100758796612363, 'microPrec': 0.9899609317046635, 'weightPrec': 0.9908098365536963, 'macroRec': 0.9613696159629024, 'microRec': 0.9899609317046635, 'weightRec': 0.9899609317046635, 'macroF1': 0.9340678701494278, 'microF1': 0.9899609317046635, 'weightF1': 0.9902563381531023, 'subsetAcc': 0.9899609317046635, 'IoU': 0.8823973705121377, 'debris Prec': 0.8228517691313036, 'debris Rec': 0.9304798617572777, 'debris F1': 0.8733624454148472, 'debris IoU': 0.7751937984496124}\n","output_type":"stream"},{"name":"stderr","text":"epoch 47/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.0585]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8952169494920702, 'microPrec': 0.9888778992136887, 'weightPrec': 0.9903994853482102, 'macroRec': 0.9701677368888465, 'microRec': 0.9888778992136887, 'weightRec': 0.9888778992136887, 'macroF1': 0.9291224135255952, 'microF1': 0.9888778992136887, 'weightF1': 0.9893593726317756, 'subsetAcc': 0.9888778992136887, 'IoU': 0.8745502550214372, 'debris Prec': 0.7923827475329859, 'debris Rec': 0.9499534760069122, 'debris F1': 0.8640430419538145, 'debris IoU': 0.7606300888723325}\n","output_type":"stream"},{"name":"stderr","text":"epoch 48/60: 100%|██████████| 120/120 [01:33<00:00,  1.28it/s, loss=0.129] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.9165191927780495, 'microPrec': 0.9901068196429454, 'weightPrec': 0.99064903800823, 'macroRec': 0.9528196045767867, 'microRec': 0.9901068196429454, 'weightRec': 0.9901068196429454, 'macroF1': 0.9338399463047602, 'microF1': 0.9901068196429454, 'weightF1': 0.9903133553468699, 'subsetAcc': 0.9901068196429454, 'IoU': 0.8820545762690926, 'debris Prec': 0.83643009442583, 'debris Rec': 0.9125348929948159, 'debris F1': 0.872826674295159, 'debris IoU': 0.7743500084597598}\n","output_type":"stream"},{"name":"stderr","text":"epoch 49/60: 100%|██████████| 120/120 [01:33<00:00,  1.29it/s, loss=0.101] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7761618370694369\n{'macroPrec': 0.9058971648725653, 'microPrec': 0.9898768606893823, 'weightPrec': 0.9909649561149679, 'macroRec': 0.9675876291323567, 'microRec': 0.9898768606893823, 'weightRec': 0.9898768606893823, 'macroF1': 0.9343515573076163, 'microF1': 0.9898768606893823, 'weightF1': 0.9902342562926236, 'subsetAcc': 0.9898768606893823, 'IoU': 0.8828352135037618, 'debris Prec': 0.8139908256880733, 'debris Rec': 0.9435065798218796, 'debris F1': 0.8739764821769377, 'debris IoU': 0.7761618370694369}\n","output_type":"stream"},{"name":"stderr","text":"epoch 50/60: 100%|██████████| 120/120 [01:34<00:00,  1.28it/s, loss=0.0163]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.893548954460335, 'microPrec': 0.9854116027108204, 'weightPrec': 0.9879758485578417, 'macroRec': 0.9812104327124785, 'microRec': 0.9854116027108204, 'weightRec': 0.9854116027108204, 'macroF1': 0.9323442834775049, 'microF1': 0.9854116027108204, 'weightF1': 0.9861420658986165, 'subsetAcc': 0.9854116027108204, 'IoU': 0.8791819055730117, 'debris Prec': 0.7883776757012684, 'debris Rec': 0.9765312316730629, 'debris F1': 0.8724251086946531, 'debris IoU': 0.773718105486264}\n########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8974784900569361, 'microPrec': 0.9891004401364918, 'weightPrec': 0.990525244035221, 'macroRec': 0.9697082554077242, 'microRec': 0.9891004401364918, 'weightRec': 0.9891004401364918, 'macroF1': 0.9302863719958363, 'microF1': 0.9891004401364918, 'weightF1': 0.9895542176946028, 'subsetAcc': 0.9891004401364918, 'IoU': 0.8763826118946727, 'debris Prec': 0.7969517641804377, 'debris Rec': 0.9487571447560813, 'debris F1': 0.8662540202682201, 'debris IoU': 0.7640635872183268}\n","output_type":"stream"},{"name":"stderr","text":"epoch 51/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0299]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.908955018620822, 'microPrec': 0.9899090054893428, 'weightPrec': 0.9908094903977045, 'macroRec': 0.962460805493058, 'microRec': 0.9899090054893428, 'weightRec': 0.9899090054893428, 'macroF1': 0.9339066781941929, 'microF1': 0.9899090054893428, 'weightF1': 0.9902187513771301, 'subsetAcc': 0.9899090054893428, 'IoU': 0.8821378690306891, 'debris Prec': 0.8205203156971645, 'debris Rec': 0.9328060614116709, 'debris F1': 0.8730677117352493, 'debris IoU': 0.7747295208655333}\n","output_type":"stream"},{"name":"stderr","text":"epoch 52/60: 100%|██████████| 120/120 [01:30<00:00,  1.32it/s, loss=0.104] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.9042100015834238, 'microPrec': 0.9896147569358588, 'weightPrec': 0.9907269352522399, 'macroRec': 0.9659499895871675, 'microRec': 0.9896147569358588, 'weightRec': 0.9896147569358588, 'macroF1': 0.9326756453906927, 'microF1': 0.9896147569358588, 'weightF1': 0.9899831016489374, 'subsetAcc': 0.9896147569358588, 'IoU': 0.880171469811506, 'debris Prec': 0.8107380242952097, 'debris Rec': 0.9403828260002659, 'debris F1': 0.8707612776170841, 'debris IoU': 0.7711046923538067}\n","output_type":"stream"},{"name":"stderr","text":"epoch 53/60: 100%|██████████| 120/120 [01:31<00:00,  1.31it/s, loss=0.0483]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.8974066001193828, 'microPrec': 0.9891400029672123, 'weightPrec': 0.9905867638605022, 'macroRec': 0.9706233259201156, 'microRec': 0.9891400029672123, 'weightRec': 0.9891400029672123, 'macroF1': 0.9306200389373445, 'microF1': 0.9891400029672123, 'weightF1': 0.989597862263298, 'subsetAcc': 0.9891400029672123, 'IoU': 0.8769063567760786, 'debris Prec': 0.7967357397504456, 'debris Rec': 0.9506181044795959, 'debris F1': 0.8669010243045033, 'debris IoU': 0.7650708745653918}\n","output_type":"stream"},{"name":"stderr","text":"epoch 54/60: 100%|██████████| 120/120 [01:32<00:00,  1.29it/s, loss=0.0571]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 5/10 epochs\n{'macroPrec': 0.9014975566728007, 'microPrec': 0.9893674892438554, 'weightPrec': 0.9905840971246168, 'macroRec': 0.9666202611221274, 'microRec': 0.9893674892438554, 'weightRec': 0.9893674892438554, 'macroF1': 0.9313761094242077, 'microF1': 0.9893674892438554, 'weightF1': 0.9897661905091982, 'subsetAcc': 0.9893674892438554, 'IoU': 0.8781108776288622, 'debris Prec': 0.8052494034768777, 'debris Rec': 0.9420443971819753, 'debris F1': 0.8682920852732174, 'debris IoU': 0.7672404460322616}\n","output_type":"stream"},{"name":"stderr","text":"epoch 55/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.0295]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 6/10 epochs\n{'macroPrec': 0.9089798704215637, 'microPrec': 0.9898125710894614, 'weightPrec': 0.9906803693404647, 'macroRec': 0.9606536229923321, 'microRec': 0.9898125710894614, 'weightRec': 0.9898125710894614, 'macroF1': 0.9331334943448835, 'microF1': 0.9898125710894614, 'weightF1': 0.990115192361869, 'subsetAcc': 0.9898125710894614, 'IoU': 0.8809117465434945, 'debris Prec': 0.8207115181401902, 'debris Rec': 0.9291506048119101, 'debris F1': 0.8715710723192021, 'debris IoU': 0.7723756906077348}\n","output_type":"stream"},{"name":"stderr","text":"epoch 56/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.0944]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 7/10 epochs\n{'macroPrec': 0.9058481660925097, 'microPrec': 0.9897210820434202, 'weightPrec': 0.9907586224555848, 'macroRec': 0.9647912085972882, 'microRec': 0.9897210820434202, 'weightRec': 0.9897210820434202, 'macroF1': 0.9331302698449243, 'microF1': 0.9897210820434202, 'weightF1': 0.9900689554968782, 'subsetAcc': 0.9897210820434202, 'IoU': 0.8808965406983639, 'debris Prec': 0.814111809842497, 'debris Rec': 0.9378572378040675, 'debris F1': 0.8716143179221101, 'debris IoU': 0.7724436172542151}\n","output_type":"stream"},{"name":"stderr","text":"epoch 57/60: 100%|██████████| 120/120 [01:33<00:00,  1.29it/s, loss=0.0528]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 8/10 epochs\n{'macroPrec': 0.8968862034402256, 'microPrec': 0.9890954947826517, 'weightPrec': 0.990567047438911, 'macroRec': 0.970855790385563, 'microRec': 0.9890954947826517, 'weightRec': 0.9890954947826517, 'macroF1': 0.930404350731537, 'microF1': 0.9890954947826517, 'weightF1': 0.9895601085114482, 'subsetAcc': 0.9890954947826517, 'IoU': 0.8765655638262635, 'debris Prec': 0.7956744134326699, 'debris Rec': 0.9511498072577429, 'debris F1': 0.8664930976023251, 'debris IoU': 0.7644356604882218}\n","output_type":"stream"},{"name":"stderr","text":"epoch 58/60: 100%|██████████| 120/120 [01:32<00:00,  1.30it/s, loss=0.0331]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 9/10 epochs\n{'macroPrec': 0.9138116126519003, 'microPrec': 0.9898644973047822, 'weightPrec': 0.9904752207326226, 'macroRec': 0.9530771292912095, 'microRec': 0.9898644973047822, 'weightRec': 0.9898644973047822, 'macroF1': 0.9324706575589263, 'microF1': 0.9898644973047822, 'weightF1': 0.9900940190932878, 'subsetAcc': 0.9898644973047822, 'IoU': 0.8798781440120147, 'debris Prec': 0.8309850637963355, 'debris Rec': 0.9133324471620364, 'debris F1': 0.8702149890764018, 'debris IoU': 0.7702483044672384}\n","output_type":"stream"},{"name":"stderr","text":"epoch 59/60: 100%|██████████| 120/120 [01:33<00:00,  1.28it/s, loss=0.0349]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 10/10 epochs\n{'macroPrec': 0.9030427570734096, 'microPrec': 0.9894639236437367, 'weightPrec': 0.990604029762127, 'macroRec': 0.9653924490600854, 'microRec': 0.9894639236437367, 'weightRec': 0.9894639236437367, 'macroF1': 0.9317602060861983, 'microF1': 0.9894639236437367, 'weightF1': 0.9898420558375455, 'subsetAcc': 0.9894639236437367, 'IoU': 0.8787216664470519, 'debris Prec': 0.8084424869873591, 'debris Rec': 0.9393858832912402, 'debris F1': 0.8690091917980878, 'debris IoU': 0.7683609676542539}\nEarly stopping triggered at epoch 59\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"\n\n# # Save everything in a checkpoint\n# checkpoint = {\n#     'model_state_dict': model.state_dict(),\n#     'optimizer_state_dict': optimizer.state_dict(),\n#     'scheduler_state_dict': scheduler.state_dict(),\n#     'epoch': 10  # Optional: Save the epoch number\n# }\n\n# torch.save(checkpoint, 'model_checkpoint_8_epochs_bs16_iou075.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:01:49.573950Z","iopub.execute_input":"2025-05-27T21:01:49.574160Z","iopub.status.idle":"2025-05-27T21:01:49.577867Z","shell.execute_reply.started":"2025-05-27T21:01:49.574142Z","shell.execute_reply":"2025-05-27T21:01:49.577167Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"output_classes = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:01:49.578534Z","iopub.execute_input":"2025-05-27T21:01:49.578754Z","iopub.status.idle":"2025-05-27T21:01:49.597420Z","shell.execute_reply.started":"2025-05-27T21:01:49.578737Z","shell.execute_reply":"2025-05-27T21:01:49.596741Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Load the saved state_dict\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_model.pth\", map_location=device))\nmodel = model.to(device)\n# Set the model to evaluation mode\nmodel.eval()\n\nmarida_test_df = create_marida_df(MARIDA_path, 'test')\nempty_df =  pd.DataFrame(columns=marida_test_df.columns)\nmarida_test_ds = MergedSegmentationDataset_B(marida_test_df, empty_df, global_bands_mean, global_bands_std, selected_bands, transform=transformTest, standardization= standardization )\n\nmarida_testLoader = DataLoader(marida_test_ds, \n                        batch_size=batch_size, \n                        shuffle=False,\n                        collate_fn=custom_collate_fn,\n                        #worker_init_fn=worker_init_fn,\n                        #generator=torch.Generator().manual_seed(seed) \n                        )\n\ntest_metrics_history = []\nmodel.eval()\nyTrue = []\nyPredicted = []\ntestLossF = []\nwith torch.no_grad():\n    for image, target, _ in marida_testLoader:\n\n        image, target = image.to(device), target.to(device)\n        logits = model(image)\n        # print(f'image dtype {image.dtype}')\n        # print(f'logits dtype {logits.dtype}')\n        # print(f'target dtype {target.dtype}')\n        # print(f'test - target shape {target.shape}')\n        #print(f'test - logit shape {logits.shape}')\n        loss = criterion(logits, target)\n\n        logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n        logits = logits.reshape((-1,output_classes))\n        target = target.reshape(-1)\n        ###################################################################################\n        mask = target != -1\n        ###################################################################################\n        \n        # bg_logits = logits[~mask]\n        # bg_target = target[~mask]\n        \n        logits = logits[mask]\n        target = target[mask]\n        \n\n        probs = F.softmax(logits, dim=1).cpu().numpy()\n        ########### threshold #########\n        probs[probs[:, 1] < 0.7] = 0.\n        ###############################\n        print(f'test - probs shape {probs.shape}')\n        target = target.cpu().numpy()\n        # testBatches += target.shape[0]\n        testLossF.append((loss.data*target.shape[0]).tolist())\n        yPredicted += probs.argmax(1).tolist()\n        yTrue += target.tolist()\n\n\n        # bg_probs = torch.nn.functional.softmax(bg_logits, dim=1).cpu().numpy()\n        # bg_target = bg_target.cpu().numpy()\n\n        # bg_yPredicted += bg_probs.argmax(1).tolist()\n        # bg_yTrue += bg_target.tolist()\n    \n    yPredicted = np.asarray(yPredicted)\n    yTrue = np.asarray(yTrue)\n    acc = Evaluation(yPredicted, yTrue)\n    test_metrics_history.append(acc)\n\n\n    # bg_yPredicted = np.asarray(bg_yPredicted)\n    # bg_yTrue = np.asarray(bg_yTrue)\n    # bg_acc = Evaluation(bg_yPredicted, bg_yTrue)\n    print(acc)\n                    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:05:49.687781Z","iopub.execute_input":"2025-05-27T21:05:49.688034Z","iopub.status.idle":"2025-05-27T21:06:05.770043Z","shell.execute_reply.started":"2025-05-27T21:05:49.688017Z","shell.execute_reply":"2025-05-27T21:06:05.769361Z"}},"outputs":[{"name":"stdout","text":"test - probs shape (7393, 2)\ntest - probs shape (11849, 2)\ntest - probs shape (5127, 2)\ntest - probs shape (2705, 2)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/1683949948.py:4: RuntimeWarning: invalid value encountered in less\n  invalid_mask |= image < -1.5\n/tmp/ipykernel_35/1683949948.py:5: RuntimeWarning: invalid value encountered in greater\n  invalid_mask |= image > 1.5\n","output_type":"stream"},{"name":"stdout","text":"test - probs shape (15895, 2)\ntest - probs shape (8950, 2)\ntest - probs shape (14047, 2)\ntest - probs shape (1506, 2)\ntest - probs shape (2329, 2)\ntest - probs shape (2431, 2)\ntest - probs shape (8477, 2)\ntest - probs shape (3649, 2)\ntest - probs shape (23416, 2)\ntest - probs shape (2931, 2)\ntest - probs shape (7485, 2)\ntest - probs shape (24819, 2)\ntest - probs shape (1738, 2)\ntest - probs shape (18112, 2)\ntest - probs shape (19052, 2)\ntest - probs shape (4814, 2)\ntest - probs shape (3349, 2)\ntest - probs shape (4305, 2)\ntest - probs shape (484, 2)\n{'macroPrec': 0.9237364290040153, 'microPrec': 0.9970081544469704, 'weightPrec': 0.9971883552272935, 'macroRec': 0.9633416893004947, 'microRec': 0.9970081544469704, 'weightRec': 0.9970081544469704, 'macroF1': 0.9426290898036325, 'microF1': 0.9970081544469704, 'weightF1': 0.9970749408837221, 'subsetAcc': 0.9970081544469704, 'IoU': 0.8967766434076173, 'debris Prec': 0.8483835005574136, 'debris Rec': 0.9288039056143206, 'debris F1': 0.8867741308992038, 'debris IoU': 0.7965806001395673}\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"#! cp best_model.pth model_50_epochs_ratio_1_20_bs16_test_iou_debris_076_thr0.8.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:02:20.999165Z","iopub.execute_input":"2025-05-27T21:02:20.999391Z","iopub.status.idle":"2025-05-27T21:02:21.002976Z","shell.execute_reply.started":"2025-05-27T21:02:20.999374Z","shell.execute_reply":"2025-05-27T21:02:21.002114Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# All black\n# /kaggle/input/litter-windrows-patches/patches/S2A_MSIL1C_20180916T101021_R022_T33TUL/S2A_MSIL1C_20180916T101021_R022_T33TUL_366560_5053920.tif","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:02:21.003957Z","iopub.execute_input":"2025-05-27T21:02:21.004262Z","iopub.status.idle":"2025-05-27T21:02:21.021533Z","shell.execute_reply.started":"2025-05-27T21:02:21.004237Z","shell.execute_reply":"2025-05-27T21:02:21.020801Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"#Lightning implementation. To be used later.\n\n# class BinaryClassificationModel(pl.LightningModule):\n#     def __init__(self, hparams):\n#         super().__init__()\n#         self.save_hyperparameters(hparams)\n\n#         # Model selection\n#         if hparams.model_name == \"resattunet\":\n#             self.model = ResidualAttentionUNet(11, 11)\n#             # Modify for binary classification\n#             self.model.decoder = nn.Sequential(\n#                 self.model.decoder,\n#                 nn.AdaptiveAvgPool2d(1),\n#                 nn.Flatten(),\n#                 nn.Linear(11, 2)  # Binary output\n#             )\n#         elif hparams.model_name == \"attunet\":\n#             self.model = AttentionUNet(11, 11)\n#             self.model.decoder = nn.Sequential(\n#                 self.model.decoder,\n#                 nn.AdaptiveAvgPool2d(1),\n#                 nn.Flatten(),\n#                 nn.Linear(11, 2)\n#             )\n#         elif hparams.model_name == \"unet\":\n#             self.model = UNet(11, 11)\n#             self.model.decoder = nn.Sequential(\n#                 self.model.decoder,\n#                 nn.AdaptiveAvgPool2d(1),\n#                 nn.Flatten(),\n#                 nn.Linear(11, 2)\n#             )\n#         else:\n#             raise ValueError(\"Invalid model name\")\n\n#         # Loss function\n#         if hparams.focal_loss:\n#             self.criterion = FocalLoss()\n#         else:\n#             weight = gen_weights(class_distr, c=1.03)[:2]  # Binary classes\n#             self.criterion = nn.CrossEntropyLoss(weight=weight, ignore_index=-1)\n\n#         # Track best metrics\n#         self.best_macro_f1 = 0.0\n#         self.best_micro_f1 = 0.0\n#         self.best_weight_f1 = 0.0\n\n#     def forward(self, x):\n#         return self.model(x)\n\n#     def training_step(self, batch, batch_idx):\n#         images, labels, _ = batch\n#         logits = self(images)\n#         loss = self.criterion(logits, labels)\n#         self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n#         return loss\n\n#     def validation_step(self, batch, batch_idx):\n#         images, labels, _ = batch\n#         logits = self(images)\n#         loss = self.criterion(logits, labels)\n#         probs = torch.softmax(logits, dim=1).cpu().numpy()\n#         labels = labels.cpu().numpy()\n#         preds = probs.argmax(1)\n#         return {\"loss\": loss, \"preds\": preds.tolist(), \"labels\": labels.tolist()}\n\n#     def validation_epoch_end(self, outputs):\n#         preds = np.concatenate([o[\"preds\"] for o in outputs])\n#         labels = np.concatenate([o[\"labels\"] for o in outputs])\n#         loss = torch.stack([o[\"loss\"] for o in outputs]).mean()\n#         acc = Evaluation(preds, labels)\n\n#         self.log(\"val_loss\", loss, prog_bar=True)\n#         self.log(\"val_macro_precision\", acc[\"macroPrec\"], prog_bar=True)\n#         self.log(\"val_macro_recall\", acc[\"macroRec\"])\n#         self.log(\"val_macro_f1\", acc[\"macroF1\"])\n#         self.log(\"val_micro_precision\", acc[\"microPrec\"])\n#         self.log(\"val_micro_recall\", acc[\"microRec\"])\n#         self.log(\"val_micro_f1\", acc[\"microF1\"])\n#         self.log(\"val_weight_precision\", acc[\"weightPrec\"])\n#         self.log(\"val_weight_recall\", acc[\"weightRec\"])\n#         self.log(\"val_weight_f1\", acc[\"weightF1\"])\n#         self.log(\"val_iou\", acc[\"IoU\"])\n\n#         # Update best metrics\n#         if acc[\"macroF1\"] > self.best_macro_f1:\n#             self.best_macro_f1 = acc[\"macroF1\"]\n#         if acc[\"microF1\"] > self.best_micro_f1:\n#             self.best_micro_f1 = acc[\"microF1\"]\n#         if acc[\"weightF1\"] > self.best_weight_f1:\n#             self.best_weight_f1 = acc[\"weightF1\"]\n\n#     def configure_optimizers(self):\n#         optimizer = optim.Adam(\n#             self.parameters(),\n#             lr=self.hparams.initial_lr,\n#             weight_decay=self.hparams.decay_lr\n#         )\n#         if self.hparams.scheduler_lr == \"rop\":\n#             scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n#                 optimizer, mode=\"min\", factor=0.1, patience=10, verbose=True\n#             )\n#             return {\n#                 \"optimizer\": optimizer,\n#                 \"lr_scheduler\": scheduler,\n#                 \"monitor\": \"val_loss\"\n#             }\n#         else:\n#             scheduler = optim.lr_scheduler.MultiStepLR(\n#                 optimizer, milestones=[40, 80, 120, 160], gamma=0.5, verbose=True\n#             )\n#             return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n\n#     def train_dataloader(self):\n#         transform = transforms.Compose([\n#             transforms.ToTensor(),\n#             RandomRotationTransform([-90, 0, 90, 180]),\n#             transforms.RandomHorizontalFlip(),\n#             transforms.Normalize(bands_mean, bands_std)\n#         ])\n#         dataset = MergedSegmentationDataset(\n#             dataset1_paths=(\"path/to/dataset1/images\", \"path/to/dataset1/masks\"),\n#             dataset2_paths=(\"path/to/dataset2/images\", \"path/to/dataset2/masks\"),\n#             transform=transform\n#         )\n#         return DataLoader(\n#             dataset,\n#             batch_size=self.hparams.train_batch_size,\n#             shuffle=True,\n#             num_workers=4,\n#             worker_init_fn=seed_worker,\n#             generator=torch.Generator().manual_seed(0)\n#         )\n\n#     def val_dataloader(self):\n#         transform = transforms.Compose([\n#             transforms.ToTensor(),\n#             transforms.Normalize(bands_mean, bands_std)\n#         ])\n#         dataset = MergedSegmentationDataset(\n#             dataset1_paths=(\"path/to/dataset1/images\", \"path/to/dataset1/masks\"),\n#             dataset2_paths=(\"path/to/dataset2/images\", \"path/to/dataset2/masks\"),\n#             transform=transform\n#         )\n#         return DataLoader(\n#             dataset,\n#             batch_size=self.hparams.test_batch_size,\n#             shuffle=False,\n#             num_workers=4,\n#             worker_init_fn=seed_worker,\n#             generator=torch.Generator().manual_seed(0)\n#         )\n\n# def seed_worker(worker_id):\n#     worker_seed = torch.initial_seed() % 2**32\n#     np.random.seed(worker_seed)\n#     random.seed(worker_seed)\n\n# def main():\n#     parser = argparse.ArgumentParser()\n#     parser.add_argument('--train_batch_size', type=int, default=8)\n#     parser.add_argument('--test_batch_size', type=int, default=4)\n#     parser.add_argument('--total_epochs', type=int, default=50)\n#     parser.add_argument('--experiment_name', type=str, required=True)\n#     parser.add_argument('--initial_lr', type=float, default=1e-3)\n#     parser.add_argument('--decay_lr', type=float, default=0)\n#     parser.add_argument('--scheduler_lr', type=str, default=\"ms\")\n#     parser.add_argument('--focal_loss', type=bool, default=False)\n#     parser.add_argument('--model_name', type=str, default=\"resattunet\")\n#     args = parser.parse_args()\n\n#     # Set seeds for reproducibility\n#     pl.seed_everything(0, workers=True)\n\n#     # Initialize model\n#     model = BinaryClassificationModel(args)\n\n#     # Logger\n#     logger = TensorBoardLogger(save_dir=args.experiment_name, name=\"logs\")\n\n#     # Callbacks for saving best models\n#     checkpoint_macro = ModelCheckpoint(\n#         dirpath=args.experiment_name,\n#         filename=\"bestMacroF1Model\",\n#         monitor=\"val_macro_f1\",\n#         mode=\"max\",\n#         save_top_k=1\n#     )\n#     checkpoint_micro = ModelCheckpoint(\n#         dirpath=args.experiment_name,\n#         filename=\"bestMicroF1Model\",\n#         monitor=\"val_micro_f1\",\n#         mode=\"max\",\n#         save_top_k=1\n#     )\n#     checkpoint_weight = ModelCheckpoint(\n#         dirpath=args.experiment_name,\n#         filename=\"bestWeightF1Model\",\n#         monitor=\"val_weight_f1\",\n#         mode=\"max\",\n#         save_top_k=1\n#     )\n\n#     # Trainer\n#     trainer = pl.Trainer(\n#         max_epochs=args.total_epochs,\n#         accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n#         devices=1,\n#         logger=logger,\n#         callbacks=[checkpoint_macro, checkpoint_micro, checkpoint_weight],\n#         deterministic=True\n#     )\n\n#     # Train\n#     trainer.fit(model)\n\n# # if __name__ == \"__main__\":\n# #     main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:02:21.022288Z","iopub.execute_input":"2025-05-27T21:02:21.022556Z","iopub.status.idle":"2025-05-27T21:02:21.040057Z","shell.execute_reply.started":"2025-05-27T21:02:21.022538Z","shell.execute_reply":"2025-05-27T21:02:21.039352Z"}},"outputs":[],"execution_count":55}]}