{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install numpy\n",
        "! pip install rasterio\n",
        "! pip install torchgeo\n",
        "! pip install segmentation-models-pytorch"
      ],
      "metadata": {
        "id": "CgSJXwH41OCP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6fe775a5-bd05-4cb7-893c-8c1e9fd9f456"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.1)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n",
            "Collecting torchgeo\n",
            "  Downloading torchgeo-0.6.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (0.8.1)\n",
            "Collecting fiona>=1.8.21 (from torchgeo)\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia>=0.7.3 (from torchgeo)\n",
            "  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lightly!=1.4.26,>=1.4.5 (from torchgeo)\n",
            "  Downloading lightly-1.5.19-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting lightning!=2.3.*,>=2 (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (2.2.2)\n",
            "Requirement already satisfied: pillow>=8.4 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (11.1.0)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (3.7.1)\n",
            "Requirement already satisfied: rasterio!=1.4.0,!=1.4.1,!=1.4.2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (1.4.3)\n",
            "Collecting rtree>=1 (from torchgeo)\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting segmentation-models-pytorch>=0.2 (from torchgeo)\n",
            "  Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (2.0.7)\n",
            "Requirement already satisfied: timm>=0.4.12 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (1.0.15)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (2.6.0+cu124)\n",
            "Collecting torchmetrics>=0.10 (from torchgeo)\n",
            "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torchvision>=0.14 in /usr/local/lib/python3.11/dist-packages (from torchgeo) (0.21.0+cu124)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from fiona>=1.8.21->torchgeo) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from fiona>=1.8.21->torchgeo) (2025.1.31)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.11/dist-packages (from fiona>=1.8.21->torchgeo) (8.1.8)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.11/dist-packages (from fiona>=1.8.21->torchgeo) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from fiona>=1.8.21->torchgeo) (0.7.2)\n",
            "Collecting kornia_rs>=0.1.0 (from kornia>=0.7.3->torchgeo)\n",
            "  Downloading kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kornia>=0.7.3->torchgeo) (24.2)\n",
            "Collecting hydra-core>=1.0.0 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightly_utils~=0.0.0 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (1.17.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (4.67.1)\n",
            "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.10.6)\n",
            "Collecting pytorch_lightning>=1.0.4 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.3.0)\n",
            "Collecting aenum>=3.1.11 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (4.12.2)\n",
            "Collecting jsonargparse<5.0,>=4.27.7 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading jsonargparse-4.37.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting omegaconf<3.0,>=2.2.3 (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: rich<14.0,>=12.3.0 in /usr/local/lib/python3.11/dist-packages (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (13.9.4)\n",
            "Collecting tensorboardX<3.0,>=2.2 (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting bitsandbytes<1.0,>=0.45.2 (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->torchgeo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->torchgeo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->torchgeo) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->torchgeo) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->torchgeo) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.3->torchgeo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.3->torchgeo) (2025.1)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio!=1.4.0,!=1.4.1,!=1.4.2,>=1.3->torchgeo) (2.4.0)\n",
            "Collecting efficientnet-pytorch>=0.6.1 (from segmentation-models-pytorch>=0.2->torchgeo)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch>=0.2->torchgeo) (0.29.3)\n",
            "Collecting pretrainedmodels>=0.7.1 (from segmentation-models-pytorch>=0.2->torchgeo)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=0.4.12->torchgeo) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchgeo) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchgeo) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchgeo) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchgeo) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchgeo) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchgeo) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->torchgeo)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchgeo) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->torchgeo) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->torchgeo) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (3.11.14)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (0.16)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (75.1.0)\n",
            "Collecting munch (from pretrainedmodels>=0.7.1->segmentation-models-pytorch>=0.2->torchgeo)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly!=1.4.26,>=1.4.5->torchgeo) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly!=1.4.26,>=1.4.5->torchgeo) (3.10)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (2.18.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX<3.0,>=2.2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (5.29.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->torchgeo) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (0.1.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (6.5.2)\n",
            "Downloading torchgeo-0.6.2-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.7/454.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.8.0-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly-1.5.19-py3-none-any.whl (850 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m850.8/850.8 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segmentation_models_pytorch-0.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.0-py3-none-any.whl (960 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonargparse-4.37.0-py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.3/216.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Downloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, antlr4-python3-runtime, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=fd9c07242263a9c365ef99b394706b500065ad04be298bdc781783cecde045c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=2f970f3e510d454e915a6636e13c13117c8f1b2deeae179fefe68d37c7c982f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=c34c60e069665f0e45d14622c2a842c04b963a23f9120a8e478b0bbd54dbe2dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/5b/96/fd94bc35962d7c6b699e8814db545155ac91d2b95785e1b035\n",
            "Successfully built efficientnet-pytorch antlr4-python3-runtime pretrainedmodels\n",
            "Installing collected packages: antlr4-python3-runtime, aenum, typeshed-client, tensorboardX, rtree, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, lightning-utilities, lightly_utils, kornia_rs, jsonargparse, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, fiona, nvidia-cusolver-cu12, torchmetrics, kornia, efficientnet-pytorch, bitsandbytes, pytorch_lightning, pretrainedmodels, segmentation-models-pytorch, lightning, lightly, torchgeo\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aenum-3.1.15 antlr4-python3-runtime-4.9.3 bitsandbytes-0.45.3 efficientnet-pytorch-0.7.1 fiona-1.10.1 hydra-core-1.3.2 jsonargparse-4.37.0 kornia-0.8.0 kornia_rs-0.1.8 lightly-1.5.19 lightly_utils-0.0.2 lightning-2.5.1 lightning-utilities-0.14.2 munch-4.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 pretrainedmodels-0.7.4 pytorch_lightning-2.5.1 rtree-1.4.0 segmentation-models-pytorch-0.4.0 tensorboardX-2.6.2.2 torchgeo-0.6.2 torchmetrics-1.7.0 typeshed-client-2.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "feb3c3dd30f743c296d56fae1dee3a9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: efficientnet-pytorch>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (11.1.0)\n",
            "Requirement already satisfied: pretrainedmodels>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.17.0)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.15)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.12.2)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.11/dist-packages (from pretrainedmodels>=0.7.1->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=0.9->segmentation-models-pytorch) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.1.31)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Mounts Drive at /content/drive\n",
        "\n",
        "# Step 2: Define paths\n",
        "zip_file_drive = '/content/drive/MyDrive/OmdenaTriestePlasticDebris2025/Data/MARIDA.zip'  # Replace with your ZIP file path in Drive\n",
        "zip_file_colab = '/content/file.zip'  # Destination path in Colab\n",
        "\n",
        "# Step 3: Copy the ZIP file from Drive to Colab\n",
        "import shutil\n",
        "shutil.copy(zip_file_drive, zip_file_colab)\n",
        "print(f\"Copied {zip_file_drive} to {zip_file_colab}\")\n",
        "\n",
        "# Step 4: Unzip the file\n",
        "import zipfile\n",
        "extract_dir = '/content/MARIDA'  # Directory where contents will be extracted\n",
        "with zipfile.ZipFile(zip_file_colab, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "print(f\"Unzipped {zip_file_colab} to {extract_dir}\")\n",
        "\n",
        "# Optional: List extracted files to verify\n",
        "import os\n",
        "extracted_files = os.listdir(extract_dir)\n",
        "print(\"Extracted files:\", extracted_files)"
      ],
      "metadata": {
        "id": "IuUmj19M9ysg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55e1bc4-20dd-422f-ec3a-f441e486bb14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Copied /content/drive/MyDrive/OmdenaTriestePlasticDebris2025/Data/MARIDA.zip to /content/file.zip\n",
            "Unzipped /content/file.zip to /content/MARIDA\n",
            "Extracted files: ['splits', 'patches', 'shapefiles', 'labels_mapping.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def extract_date_tile(filename):\n",
        "    \"\"\"Extract date and tile from filename using regex.\"\"\"\n",
        "    pattern = r'^(\\d{1,2}-\\d{1,2}-\\d{2})_([A-Z0-9]+)_\\d+$'\n",
        "    match = re.match(pattern, filename)\n",
        "    if not match:\n",
        "        raise ValueError(f\"Invalid filename format: {filename}\")\n",
        "    return match.groups()  # Returns tuple (date, tile)\n",
        "\n",
        "def create_marida_df(data_path, mode='train'):\n",
        "    \"\"\"Create DataFrame from MARIDA dataset files.\"\"\"\n",
        "    # Determine split file based on mode\n",
        "    split_files = {'train': 'train_X.txt', 'val': 'val_X.txt', 'test': 'test_X.txt'}\n",
        "    items_list_path = os.path.join(data_path, 'splits', split_files[mode])\n",
        "\n",
        "    # Read items list\n",
        "    with open(items_list_path, 'r') as file:\n",
        "        items = [item.strip() for item in file]\n",
        "\n",
        "    # Base path for patches\n",
        "    items_path = os.path.join(data_path, 'patches')\n",
        "\n",
        "    # Prepare data lists\n",
        "    data = {\n",
        "        'image': [],\n",
        "        'mask': [],\n",
        "        'confidence': [],\n",
        "        'date': [],\n",
        "        'tile': []\n",
        "    }\n",
        "\n",
        "    # Process each item\n",
        "    for item in items:\n",
        "        tile = \"_\".join(item.split(\"_\")[:-1])\n",
        "        tile_path = os.path.join(items_path, f\"S2_{tile}\")\n",
        "\n",
        "        # Define file paths\n",
        "        base_name = f'S2_{item}'\n",
        "        paths = {\n",
        "            'image': os.path.join(tile_path, f'{base_name}.tif'),\n",
        "            'mask': os.path.join(tile_path, f'{base_name}_cl.tif'),\n",
        "            'confidence': os.path.join(tile_path, f'{base_name}_conf.tif')\n",
        "        }\n",
        "\n",
        "        # Check if all files exist\n",
        "        if all(os.path.exists(p) for p in paths.values()):\n",
        "            data['image'].append(paths['image'])\n",
        "            data['mask'].append(paths['mask'])\n",
        "            data['confidence'].append(paths['confidence'])\n",
        "            date, tile = extract_date_tile(item)\n",
        "            data['date'].append(date)\n",
        "            data['tile'].append(tile)\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# MARIDA labels dictionary\n",
        "MARIDA_LABELS = {\n",
        "    i: label for i, label in enumerate([\n",
        "        'Marine Debris', 'Dense Sargassum', 'Sparse Sargassum', 'Natural Organic Material',\n",
        "        'Ship', 'Clouds', 'Marine Water', 'Sediment-Laden Water', 'Foam', 'Turbid Water',\n",
        "        'Shallow Water', 'Waves', 'Cloud Shadows', 'Wakes', 'Mixed Water'\n",
        "    ], 1)\n",
        "}\n",
        "\n",
        "# Load and process labels mapping\n",
        "def load_labels_mapping(file_path):\n",
        "    \"\"\"Load and convert labels mapping to DataFrame.\"\"\"\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return pd.DataFrame.from_dict(\n",
        "        data,\n",
        "        orient='index',\n",
        "        columns=[MARIDA_LABELS[i] for i in range(1, 16)]\n",
        "    ).reset_index().rename(columns={'index': 'image_name'})\n",
        "\n"
      ],
      "metadata": {
        "id": "VNPNJCFTzp7L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_path = '/content/MARIDA'\n",
        "df = create_marida_df(data_path, 'train')\n",
        "\n",
        "# Load labels mapping\n",
        "# Assigns to each example the set of classes corresponding to the pixels in the imag\n",
        "labels_df = load_labels_mapping(os.path.join(data_path, 'labels_mapping.txt'))\n",
        "print(labels_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apDzocHsXtE2",
        "outputId": "6cb2a63d-2a77-42cb-eb9a-2be8251bdbc2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  image_name  Marine Debris  Dense Sargassum  \\\n",
            "0     S2_1-12-19_48MYU_0.tif              0                0   \n",
            "1     S2_1-12-19_48MYU_1.tif              0                0   \n",
            "2     S2_1-12-19_48MYU_2.tif              1                0   \n",
            "3     S2_1-12-19_48MYU_3.tif              1                0   \n",
            "4     S2_11-1-19_19QDA_0.tif              0                0   \n",
            "...                      ...            ...              ...   \n",
            "1376  S2_9-10-17_16PEC_5.tif              0                0   \n",
            "1377  S2_9-10-17_16PEC_6.tif              0                0   \n",
            "1378  S2_9-10-17_16PEC_7.tif              0                0   \n",
            "1379  S2_9-10-17_16PEC_8.tif              0                0   \n",
            "1380  S2_9-10-17_16PEC_9.tif              0                0   \n",
            "\n",
            "      Sparse Sargassum  Natural Organic Material  Ship  Clouds  Marine Water  \\\n",
            "0                    0                         0     1       0             1   \n",
            "1                    0                         0     0       0             1   \n",
            "2                    0                         0     1       0             1   \n",
            "3                    0                         0     1       0             1   \n",
            "4                    0                         0     1       0             1   \n",
            "...                ...                       ...   ...     ...           ...   \n",
            "1376                 0                         0     0       0             1   \n",
            "1377                 0                         0     0       0             1   \n",
            "1378                 0                         0     0       0             0   \n",
            "1379                 0                         0     0       1             0   \n",
            "1380                 0                         0     0       0             1   \n",
            "\n",
            "      Sediment-Laden Water  Foam  Turbid Water  Shallow Water  Waves  \\\n",
            "0                        0     0             0              0      0   \n",
            "1                        0     0             0              0      0   \n",
            "2                        0     0             0              0      0   \n",
            "3                        0     0             0              0      0   \n",
            "4                        0     0             0              0      0   \n",
            "...                    ...   ...           ...            ...    ...   \n",
            "1376                     0     0             0              0      0   \n",
            "1377                     0     0             0              0      0   \n",
            "1378                     0     1             0              0      0   \n",
            "1379                     0     0             0              0      0   \n",
            "1380                     0     0             0              0      0   \n",
            "\n",
            "      Cloud Shadows  Wakes  Mixed Water  \n",
            "0                 0      1            0  \n",
            "1                 0      0            0  \n",
            "2                 0      0            0  \n",
            "3                 0      1            0  \n",
            "4                 0      0            0  \n",
            "...             ...    ...          ...  \n",
            "1376              0      0            0  \n",
            "1377              0      0            0  \n",
            "1378              0      0            0  \n",
            "1379              1      0            0  \n",
            "1380              0      0            0  \n",
            "\n",
            "[1381 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import rasterio\n",
        "import numpy as np\n",
        "\n",
        "class MARIDADataset(Dataset):\n",
        "    \"\"\"\n",
        "    Provides images and masks for the MARIDA dataset.\n",
        "\n",
        "    Initializes from a pandas DataFrame containing absolute paths to images and masks.\n",
        "\n",
        "    Adds 2 null bands to ensure compatibility between pretrained TorchGeo weights (13 bands) and MARIDA imagery.\n",
        "\n",
        "    Handles NaN values by resetting them to 0.\n",
        "\n",
        "    Transforms MARIDA labels (15 classes) into binary labels: 1 for debris and 0 for no debris.\n",
        "\n",
        "    Applies z normalization to images\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, df, means, stds, transform=None):\n",
        "        \"\"\"\n",
        "        Args :\n",
        "            df (pd.DataFrame) : dataframe with columns including image and\n",
        "                                mask's  absolute paths\n",
        "            means : band-wise mean computed on MARIDA\n",
        "            stds : band-wise standard deviation computed on MARIDA\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.means = torch.tensor(means, dtype=torch.float32)  # 11 bands\n",
        "        self.stds = torch.tensor(stds, dtype=torch.float32)    # 11 bands\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image (11 bands from MARIDA, already in reflectance range)\n",
        "        with rasterio.open(self.df.iloc[idx]['image']) as src:\n",
        "            image = src.read().astype(np.float32)\n",
        "\n",
        "        # Load mask\n",
        "        with rasterio.open(self.df.iloc[idx]['mask']) as src:\n",
        "            mask = src.read(1).astype(np.int64) # Read mask as int64\n",
        "            mask = (mask == 1).astype(np.int64)  # Set class 1 to 1, all else to 0\n",
        "\n",
        "        # Convert to torch tensors\n",
        "        #image = torch.tensor(image)  # Shape: [11, H, W]\n",
        "        image = torch.tensor(np.nan_to_num(image, nan=0.0))  # Replace NaNs\n",
        "        mask = torch.tensor(mask)    # Shape: [H, W]\n",
        "\n",
        "        # Normalize the 11 bands\n",
        "        image = (image - self.means[:, None, None]) / self.stds[:, None, None]\n",
        "\n",
        "        # Expand to 13 bands for TorchGeo pretrained model compatibility\n",
        "        full_image = torch.zeros(13, image.shape[1], image.shape[2])\n",
        "        band_mapping = [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11]  # Skipping B9, B10\n",
        "        full_image[band_mapping] = image\n",
        "        if self.transform:\n",
        "          # Apply any transforms (e.g., resizing, normalization)\n",
        "          full_image = self.transform(full_image)\n",
        "          mask = self.transform(mask)\n",
        "        return full_image, mask\n",
        "\n"
      ],
      "metadata": {
        "id": "q7uICNCkcdTB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "\n",
        "def compute_marida_stats(df, num_bands=11):\n",
        "    \"\"\"\n",
        "    Compute per-band mean and std from MARIDA GeoTIFFs, handling NaN values.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame with 'image' column containing GeoTIFF paths.\n",
        "        num_bands (int): Number of bands in each image (11 for MARIDA).\n",
        "\n",
        "    Returns:\n",
        "        means (np.ndarray): Mean for each band (NaN-safe).\n",
        "        stds (np.ndarray): Standard deviation for each band (NaN-safe).\n",
        "    \"\"\"\n",
        "    # Initialize accumulators\n",
        "    band_sums = np.zeros(num_bands, dtype=np.float64)\n",
        "    band_sumsq = np.zeros(num_bands, dtype=np.float64)  # For sum of squares\n",
        "    total_valid_pixels_per_band = np.zeros(num_bands, dtype=np.int64)\n",
        "\n",
        "    # Process each image\n",
        "    for img_path in df['image']:\n",
        "        with rasterio.open(img_path) as src:\n",
        "            image = src.read().astype(np.float32)\n",
        "            assert image.shape[0] == num_bands, f\"Expected {num_bands} bands, got {image.shape[0]}\"\n",
        "\n",
        "            # Mask NaN and invalid values (e.g., <= 0 could be no-data)\n",
        "            valid_mask = np.logical_and(np.isfinite(image), image > 0)  # True where valid\n",
        "            image[~valid_mask] = 0  # Set invalid to 0 for sum calculations (won’t affect valid sums)\n",
        "\n",
        "            # Sum and sum of squares per band, only for valid pixels\n",
        "            band_sums += np.sum(image * valid_mask, axis=(1, 2))  # Multiply by mask to exclude invalid\n",
        "            band_sumsq += np.sum((image ** 2) * valid_mask, axis=(1, 2))\n",
        "            total_valid_pixels_per_band += np.sum(valid_mask, axis=(1, 2))\n",
        "\n",
        "    # Compute mean and std (handle case where no valid pixels exist)\n",
        "    means = np.where(total_valid_pixels_per_band > 0,\n",
        "                     band_sums / total_valid_pixels_per_band,\n",
        "                     np.nan)  # NaN if no valid pixels\n",
        "    variances = np.where(total_valid_pixels_per_band > 0,\n",
        "                         band_sumsq / total_valid_pixels_per_band - (means ** 2),\n",
        "                         np.nan)\n",
        "    stds = np.sqrt(np.maximum(variances, 0))  # Ensure no negative variance due to numerical error\n",
        "\n",
        "    return means, stds\n",
        "\n",
        "# Example usage\n",
        "means_11_bands, stds_11_bands = compute_marida_stats(df[:100])\n",
        "print(\"Means:\", means_11_bands)\n",
        "print(\"Stds:\", stds_11_bands)\n",
        "\n",
        "# Save to file\n",
        "np.save('means_11_bands.npy', means_11_bands)\n",
        "np.save('stds_11_bands.npy', stds_11_bands)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyfCYrR4fq4g",
        "outputId": "596c8694-d8b5-4637-c803-c14ff4f3e72f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Means: [0.03575588 0.03161822 0.02307298 0.0145986  0.01358301 0.01731202\n",
            " 0.01975166 0.01753542 0.02012366 0.0110173  0.00692523]\n",
            "Stds: [0.01944577 0.01982479 0.02202    0.02190828 0.02336899 0.04243802\n",
            " 0.05247064 0.04990999 0.05852649 0.03215673 0.01994174]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "class WeightedDiceLoss(nn.Module):\n",
        "    def __init__(self, weights=None, smooth=1e-6):\n",
        "        \"\"\"\n",
        "        Weighted Dice Loss for multi-class segmentation.\n",
        "\n",
        "        Args:\n",
        "            weights (list or torch.Tensor): Per-class weights (length = num_classes)\n",
        "            smooth (float): Smoothing factor to avoid division by zero\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.weights = torch.tensor(weights, dtype=torch.float32) if weights is not None else None\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        preds = F.softmax(inputs, dim=1)\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=preds.shape[1]).permute(0, 3, 1, 2).float()\n",
        "\n",
        "        weights = self.weights.to(inputs.device) if self.weights is not None else torch.ones(preds.shape[1], device=inputs.device)\n",
        "\n",
        "        intersection = (preds * targets_one_hot).sum(dim=(2, 3))\n",
        "        union = preds.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))\n",
        "\n",
        "        dice_score = (2. * intersection + self.smooth) / (union + self.smooth)\n",
        "        weighted_dice = weights * dice_score\n",
        "        return 1 - weighted_dice.mean()"
      ],
      "metadata": {
        "id": "6XwOJrvexCwM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YvrgR4XI1J9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42b4853-91b3-408a-821b-c67574c00a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8801\n",
            "Epoch [2/10], Loss: 0.8752\n",
            "Epoch [3/10], Loss: 0.8723\n",
            "Epoch [4/10], Loss: 0.8696\n",
            "Epoch [5/10], Loss: 0.8747\n",
            "Epoch [6/10], Loss: 0.8750\n",
            "Epoch [7/10], Loss: 0.7382\n",
            "Epoch [8/10], Loss: 0.6024\n",
            "Epoch [9/10], Loss: 0.6029\n",
            "Epoch [10/10], Loss: 0.6029\n",
            "Training complete. Model saved as 'unetpp_marida.pth'.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import segmentation_models_pytorch as smp\n",
        "from torchgeo.models import ResNet18_Weights\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# DataLoader\n",
        "dataset = MARIDADataset(df, means_11_bands, stds_11_bands)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "# Load pretrained weights from torchgeo\n",
        "weights = ResNet18_Weights.SENTINEL2_ALL_MOCO  # Pretrained on Sentinel-2 imagery\n",
        "in_channels = weights.meta[\"in_chans\"]  # Number of input channels (e.g., 13 for Sentinel-2)\n",
        "\n",
        "# Set up UNet++ model with pretrained ResNet18 backbone\n",
        "model = smp.UnetPlusPlus(\n",
        "    encoder_name=\"resnet18\",            # Backbone architecture\n",
        "    encoder_weights=None,               # We'll load torchgeo weights manually\n",
        "    in_channels=in_channels,            # Match Sentinel-2 bands\n",
        "    classes=2,                          # e.g., debris vs. background\n",
        "    decoder_use_batchnorm=True          # Optional: improves training stability\n",
        ")\n",
        "\n",
        "# Load pretrained weights into the encoder\n",
        "pretrained_dict = weights.get_state_dict(progress=True)\n",
        "model_dict = model.encoder.state_dict()\n",
        "# Filter compatible weights (strict=False skips mismatches)\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "model_dict.update(pretrained_dict)\n",
        "model.encoder.load_state_dict(model_dict)\n",
        "\n",
        "# Move to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "# Define class weights (example: higher weight for Marine Debris, class 1)\n",
        "class_weights = np.array([1.0, 3.0])/4.  # Emphasize class 1 (Marine Debris)\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = WeightedDiceLoss(weights=class_weights)  # Use weighted Dice Loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (images, masks) in enumerate(dataloader):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(images)  # Shape: (batch, classes, height, width\n",
        "        loss = criterion(outputs, masks)\n",
        "        # Check for NaN or Inf and log only if detected\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            print(f\"Epoch {epoch+1}, Batch {i}: NaN/Inf loss detected: {loss.item()}\")\n",
        "            if torch.any(torch.isnan(images)) or torch.any(torch.isinf(images)):\n",
        "                print(f\"  - Images contain NaN: {torch.any(torch.isnan(images))}, Inf: {torch.any(torch.isinf(images))}\")\n",
        "            if torch.any(torch.isnan(outputs)) or torch.any(torch.isinf(outputs)):\n",
        "                print(f\"  - Outputs contain NaN: {torch.any(torch.isnan(outputs))}, Inf: {torch.any(torch.isinf(outputs))}\")\n",
        "            break  # Stop if NaN/Inf is found\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"unetpp_marida.pth\")\n",
        "print(\"Training complete. Model saved as 'unetpp_marida.pth'.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzCTY589dIQt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}